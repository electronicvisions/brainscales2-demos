{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5884abe",
   "metadata": {},
   "source": [
    "# Partitioning of Feedforward SNNs\n",
    "\n",
    "In this tutorial we will discuss network partitioning for feedforward networks on BrainScaleS-2 (BSS-2) [1].\n",
    "We will create a spiking neural network (SNN) in `hxtorch.snn` [2] based on the output of a partitioning algorithm and train it with BSS-2 in-the-loop with the surrogate gradient (SG) method [3] to solve the MNIST [4] task.\n",
    "This experiment has been published in [5].\n",
    "\n",
    "If you are not familiar with `hxtorch.snn` or the BSS-2 system, you might want to do previous tutorials first or take a look at the following references.\n",
    "This tutorial will not detail their corresponding working principles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef137fe4",
   "metadata": {},
   "source": [
    "## References and further reading\n",
    "\n",
    "[1] Pehle, C., Billaudelle, S., Cramer, B., Kaiser, J., Schreiber, K.,\n",
    "Stradmann, Y., Weis, J., Leibfried, A., Müller, E., and Schemmel, J. The\n",
    "BrainScaleS-2 accelerated neuromorphic system with hybrid plasticity.\n",
    "Frontiers in Neuroscience, 16, 2022. ISSN 1662-453X. [doi:\n",
    "10.3389/fnins.2022.795876](https://www.frontiersin.org/articles/10.3389/fnins.2022.795876/full).\n",
    "\n",
    "[2] Spilger, P., Arnold, E., Blessing, L., Mauch, C., Pehle, C., Müller,\n",
    "E., and Schemmel, J. hxtorch.snn: Machine- learning-inspired spiking\n",
    "neural network modeling on BrainScaleS-2. 2023. [doi:\n",
    "10.48550.2212.12210](https://doi.org/10.48550/arXiv.2212.12210)\n",
    "\n",
    "[3] Emre O. Neftci, Hesham Mostafa, and Friedemann Zenke. 2019.\n",
    "Surrogate gradi- ent learning in spiking neural networks: Bringing the\n",
    "power of gradient-based optimization to spiking neural networks. IEEE\n",
    "Signal Processing Magazine 36, 6 (2019),51–63.\n",
    "[https://doi.org/10.1109/MSP.2019.2931595](https://doi.org/10.1109/MSP.2019.2931595)\n",
    "\n",
    "[4] Yann LeCun and Corinna Cortes. The MNIST database of handwritten\n",
    "digits. 1998.\n",
    "\n",
    "[5] Arnold, E., Spilger, P., Straub, J. V., Müller, E., Dold, D., Meoni,\n",
    "G., Schemmel, J. Scalable Network Emulation on Analog Neuromorphic\n",
    "Hardware. Frontiers in Neuroscience. 2025. [doi:\n",
    "10.3389/fnins.2024.1523331](https://doi.org/10.3389/fnins.2024.1523331)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782d284",
   "metadata": {},
   "source": [
    "### A Partitioning Algorithm\n",
    "\n",
    "When working with feedforward neural networks, the typical network structure that arises will look like this:\n",
    "\n",
    "<img src=\"_static/tutorial/feedforward-network.jpeg\" style=\"width:60%;\" align=\"center\">\n",
    "\n",
    "The marked regions represent layers of the network and the dots the neurons within them.\n",
    "We will work with an input layer, some hidden layers and an output layer with dense synaptic connections between the neurons of consecutive layers.\n",
    "\n",
    "The BSS-2 System consists of 512 AdEx-neuron circuits with a fan-in of 256 individual synaptic connections to each of them.\n",
    "The weights of these synaptic connections can be either excitatory (positive) or inhibitory (negative) and can in each case be configured within 6 bit (inhibitory: $ [-63, ..., 0] $, excitatory: $ [0, ..., 63] $).\n",
    "To work with signed weights, we can combine two synaptic rows, one for each input type.\n",
    "This, in return, reduces the fan-in per neuron circuit to 128.\n",
    "A higher fan-in can be achieved by connecting neuron circuits on BSS-2 such that they share their membrane voltage and add their respective fan-in.\n",
    "This decreases the number of available neurons on chip.\n",
    "\n",
    "Networks requiring more neuron resources than the chip provides, need to be partitioned into subnetworks, each fitting on a single BSS-2 instance.\n",
    "As the neurons of any given layer are not interconnected and the information is propagated through the network in one direction only (feedforward), a postsynaptic layer can be split into multiple independent sublayers, each receiving all inputs from the presynaptic layer (in case of dense connections in between).\n",
    "Making use of this characteristic, we can turn this into a multi-step-process and run all the sublayers consecutively on the current single-chip BSS-2 hardware\n",
    "In the future, all parts are run in parallel on multi-chip hardware.\n",
    "After all the runs in a particular layer, we can combine their outputs and can move on to the next layer and then repeat the partitioning process\n",
    "The following image showcases this procedure:\n",
    "\n",
    "<img src=\"_static/tutorial/feedforward-partitioning_idea.jpeg\" style=\"width:60%;\" align=\"center\">\n",
    "\n",
    "We will now try to find an optimal partition for a given network.\n",
    "Let’s say it consists of $ L \\in\\mathbb{N} $ layers with $ N_l \\in\\mathbb{N} $ neurons in layer $ l \\leq L $.\n",
    "For the fully connected structure, every neuron in a following layer will have to be provided with a fan-in of the number of neurons in the previous layer ($ N_{ l-1 } $).\n",
    "We can calculate how many neurons circuits $ c_l $ have to be connected in order to achieve this fan-in:\n",
    "\n",
    "$$\n",
    "c_l = \\left\\lceil \\frac{N_{l-1}}{128}\\right\\rceil.\n",
    "$$\n",
    "\n",
    "In the next step, we want to know how many neurons of this size fit on one chip:\n",
    "\n",
    "$$\n",
    "N_{c_l} = \\left\\lfloor \\frac{512}{c_l}\\right\\rfloor.\n",
    "$$\n",
    "\n",
    "Last but not least, this implies the number of necessary partitions for a given layer:\n",
    "\n",
    "$$\n",
    "p_l = \\left\\lceil\\frac{N_l}{N_{c_l}} \\right\\rceil.\n",
    "$$\n",
    "\n",
    "We can calculate this for ech layer $ l $.\n",
    "If several consecutive layers do not need to be partitioned  ($ p_l = p_{l+1} = … = p_{l+n} = 1 $), we can also check if these parts of the network can be executed in one hardware run, i.e. fit on the chip together.\n",
    "\n",
    "`partition()` implements this algorithm. As we will chose leaky-integrator (LI) neurons in the output layer, we might want to use different calibrations for these neurons: for a simpler handling of calibration files, one might choose to calculate the output in a seperate hardware execution (this is why we have the option `seperate_output`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f5a24",
   "metadata": {},
   "source": [
    "## Try it out yourself!:\n",
    "\n",
    "The first returned list contains the numbers $ p_l $ of necessary partitions for each layer.\n",
    "They are grouped into lists by (possible and optimal) hardware runs.\n",
    "The second returned list contains the numbers $ c_l $ of neuron circuits that have to be combined in order to achieve the fan-in, again, for each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ddedf8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from _static.tutorial.partitioning_helpers import partition\n",
    "\n",
    "p = partition(layer_sizes=[28*28, 256, 246, 10], seperate_output=True)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65039c0d",
   "metadata": {},
   "source": [
    "### Example with the MNIST data set\n",
    "\n",
    "We are now going to implement an SNN in `hxtorch.snn` and put it to the test by training the resulting network on BSS-2.\n",
    "Before we can actually train a network, a few more steps have to be considered.\n",
    "\n",
    "In this example we will make use of the MNIST data set [4].\n",
    "It contains $ 28 \\times 28 $ gray scale images of the numbers from zero up to nine.\n",
    "The goal of our trained network will be to classify these images correctly.\n",
    "To do that, lets set the input space of the network to the image size: $ 28 \\times 28 = 784 $ and use a hidden layer consisting of 256 leaky-integrate-and-fire (LIF) neurons.\n",
    "The 10 leaky integrators in our output layer correspond to the ten classes of the data set\n",
    "\n",
    "How do we have to partition this network for it to be compatible with the BSS-2 hardware?\n",
    "Tip: Check the result of `partition()` if you are unsure.\n",
    "\n",
    "Let’s load the data set before we continue with the encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0f7677",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# set up hardware client\n",
    "from _static.common.helpers import setup_hardware_client\n",
    "setup_hardware_client()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from _static.tutorial.partitioning_helpers import RandomRandomRotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd760266",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device:\", dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146c87c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# define the rotation that is applied\n",
    "RotationTransform = RandomRandomRotation(dmin=-25, dmax=25, prob=0.5)\n",
    "\n",
    "transform_train = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(), RotationTransform])\n",
    "\n",
    "transform_test = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"/loh/data/mnist\", train=True, download=True,\n",
    "    transform=transform_train)\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"/loh/data/mnist\", train=False, download=True,\n",
    "    transform=transform_test)\n",
    "\n",
    "# We only train on 10% of the data to increase execution speed\n",
    "# ... comment this out if you want to train on the whole dataset\n",
    "train_data = torch.utils.data.Subset(\n",
    "    train_data, torch.arange(int(len(train_data) * 0.1)))\n",
    "test_data = torch.utils.data.Subset(\n",
    "    test_data, torch.arange(int(len(test_data) * 0.1)))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764903c6",
   "metadata": {},
   "source": [
    "As you can see, we can augment the data set by applying random rotations to some of the data to counteract overfitting.\n",
    "The probability with which these are applied and the angle range can be specified here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e103e1c",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "We have to encode the real valued input data into spike trains in order for the LIF neurons to be able to work with it.\n",
    "An encoding approach that has shown its effectiveness in the past is a time-to-first-spike (TTFS) encoding.\n",
    "We will implement it a linear manner:\n",
    "\n",
    "As hxtorch computes gradients by representing the network dynamics on a discrete time grid of length $ T $ time steps, each value of each pixel will be mapped to a discrete time-index\n",
    "$ t_{\\text{idx}} \\in\\mathbb{N} $ along a spike train of length\n",
    "$ T \\in\\mathbb{N} $ at which a spike will be placed.\n",
    "\n",
    "$$\n",
    "x \\mapsto T\\cdot \\frac{x-x_{\\text{min}}}{x_{\\text{max}}- x_{\\text{min}}} =: t_1, \\quad\n",
    "t_1 \\mapsto T - \\left\\lfloor{t}_1\\right\\rceil =: t_{\\text{idx}},\n",
    "$$\n",
    "\n",
    "where $ x_{\\text{ min/max }} $ is the minimum/maximum value of the data set.\n",
    "The mixed flooring and ceiling brackets indicate rounding to the next integer.\n",
    "\n",
    "With an encoding like this, high values are represented by early spikes and (while decreasing linearly) values close to $ x_{\\text{min}} $ result in spike times near to $ T $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba5aa34",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def ttfs_encode(x: torch.Tensor, sequence_length: int, x_min: float = 0.,\n",
    "                x_max: float = 1.) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Translate the image into a time-to-first-spike representation.\n",
    "\n",
    "    :param x: The image to encode into spikes.\n",
    "    :param sequence_length: The length of time sequence, i.e. number of time steps.\n",
    "    :param x_min: The minimum pixel value to still resulting in a spike.\n",
    "    :param x_max: The pixel value for which (and above) the spike time is at time step 0.\n",
    "\n",
    "    :return: The spiking representation of the image.\n",
    "    \"\"\"\n",
    "\n",
    "    indx = sequence_length - torch.round(\n",
    "        (sequence_length) * (x - x_min) / (x_max - x_min))\n",
    "\n",
    "    x_enc = torch.zeros([sequence_length] + list(x.shape), device=x.device)\n",
    "    for i in range(sequence_length):\n",
    "        x_enc[i] = torch.where(indx == i, 1, 0)\n",
    "\n",
    "    return x_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a006b25",
   "metadata": {},
   "source": [
    "The full pre-processing of an image is shown in the following figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8ef5d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from _static.tutorial.partitioning_plots import show_transforms\n",
    "\n",
    "fig = show_transforms(train_data, RotationTransform, partial(\n",
    "    ttfs_encode, sequence_length=30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e293e9ae",
   "metadata": {},
   "source": [
    "Note that the image in the middle might be the same as the initial image, depending on the probability of the application given to `RandomRandomRotation(..., ..., prob=...)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f910c9",
   "metadata": {},
   "source": [
    "## Decoding\n",
    "\n",
    "As we chose leaky integrators in the last layer of the network, there will be no spiking behavior in this output layer.\n",
    "We will have to apply some kind of decoding to the membrane traces that are being recorded on BSS-2 to turn them into class scores in order to infer a prediction.\n",
    "A simple method to achieve this is a max-over-time decoding: the maximum value of each membrane trace will used to derive a probability for each class label.\n",
    "For that we use the log-softmax function in conjunction with `PyTorch`’s `torch.nn.functional.nll_loss`, which corresponds to the Cross Entropy Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db1a6b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def decode(x: torch.Tensor, trace_scaling: float = 1) -> torch.Tensor:\n",
    "    x = torch.amax(x * trace_scaling, 0)\n",
    "    log_p_y = torch.nn.functional.log_softmax(x, dim=1)\n",
    "    return log_p_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16aee8a3",
   "metadata": {},
   "source": [
    "## The Model\n",
    "\n",
    "The class `SNN` creates a model in a similar fashion to the known `PyTorch` formulation.\n",
    "It defines the projections and neuron layers of the network, including a dropout layer.\n",
    "In the `forward`-method, an input is traversed through the network and the respective output is returned.\n",
    "\n",
    "The class `Model` puts together what we already have and creates a complete model with encoder, network and decoder.\n",
    "It even consists of a regularization method that might come in handy later on.\n",
    "When creating the synapses, the parameter `func` allows us to apply a function to the weights before they are used in the networks calculations.\n",
    "We will use a clamping function that has an exponential decay close to the maximum values ($ -63 $ and $ 63 $) which prohibits over-saturation of the weights as well as discrepancies between software and hardware weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d849d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import hxtorch\n",
    "import hxtorch.spiking as hxsnn\n",
    "import hxtorch.spiking.functional as F\n",
    "from hxtorch.spiking.transforms import weight_transforms\n",
    "\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cad5d8",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Synapse(hxsnn.Synapse):\n",
    "\n",
    "    def __init__(self, *args, cap: float, weight_exp_rolloff: float,\n",
    "                 use_quantization: bool, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cap = cap\n",
    "        self.weight_exp_rolloff = weight_exp_rolloff\n",
    "        self.use_quantization = use_quantization\n",
    "\n",
    "    def forward_func(self, inputs: hxsnn.NeuronHandle) -> hxsnn.SynapseHandle:\n",
    "        return hxsnn.SynapseHandle(\n",
    "            F.linear_exponential_clamp(\n",
    "                inputs.spikes, self.weight, cap=self.cap, start_weight=self.weight_exp_rolloff,\n",
    "                quantize=self.use_quantization))\n",
    "\n",
    "\n",
    "class SNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SNN consiting of a hidden LIF layer, with a subseqent dropout layer and\n",
    "    a LI output layer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            lif_params: dict,\n",
    "            li_params: dict,\n",
    "            mock: bool = True,\n",
    "            dt: float = 1.0e-6,\n",
    "            use_quantization: bool = True,\n",
    "            weight_init_hidden: Optional[Tuple[float, float]] = None,\n",
    "            weight_init_output: Optional[Tuple[float, float]] = None,\n",
    "            weight_scale_hidden: float = 1.,\n",
    "            trace_scale_hidden: float = 1.,\n",
    "            weight_scale_output: float = 1.,\n",
    "            trace_scale_output: float = 1.,\n",
    "            dropout_hidden: float = 0.,\n",
    "            weight_exp_rolloff: float = 61.,\n",
    "            device: torch.device = torch.device(\"cpu\")) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the SNN.\n",
    "\n",
    "            hardware.\n",
    "        :param lif_params: Params for LIF neurons. Also used for calibration.\n",
    "        :param li_params: Params for LI neurons. Also used for calibration.\n",
    "        :param mock: Indicating whether to train in software or on\n",
    "        :param dt: Time-binning width.\n",
    "        :param use_quantization: Wether to use discrete weights in\n",
    "            simulation forward.\n",
    "        :param weight_init_hidden: Weight initialization mean\n",
    "            and standard deviation.\n",
    "        :param weight_init_output: Output layer weight initialization mean\n",
    "            and standard deviation.\n",
    "        :param weight_scale_hidden: The factor with which the hidden\n",
    "            software weights are scaled when mapped to hardware.\n",
    "        :param trace_scale_hidden: The factor with which the membrane\n",
    "            traces of the hidden neurons are scaled when mapped from\n",
    "            hardware measurements to software.\n",
    "        :param weight_scale_output: The factor with which the output\n",
    "            software weights are scaled when mapped to hardware.\n",
    "        :param trace_scale_output: The factor with which the membrane\n",
    "            traces of the readout neurons are scaled when mapped from\n",
    "            hardware measurements to software.\n",
    "        :param dropout_hidden: Probability of hidden spike to drop out.\n",
    "        :param weight_exp_rolloff: Weights with higher absolutes are rolled off\n",
    "            exponentially in software.\n",
    "        :param device: The used PyTorch device used for tensor operations\n",
    "            in software.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.exp1 = hxsnn.Experiment(mock=mock, dt=dt)\n",
    "        self.exp1.inter_batch_entry_wait = 125 * 50  # us\n",
    "        # create morphologies\n",
    "        # using size 8 for simpler mapping\n",
    "        morph_hidden = hxsnn.morphology.SingleCompartmentNeuron(\n",
    "            size=8, expand_horizontally=False)\n",
    "        morph_output = hxsnn.morphology.SingleCompartmentNeuron(\n",
    "            size=2, expand_horizontally = False)\n",
    "\n",
    "        # create layers\n",
    "        self.linear_hidden = []\n",
    "        self.neurons_hidden = []\n",
    "        self.n_parts_hidden = 4\n",
    "        for i in range(self.n_parts_hidden):\n",
    "            execution_instance = hxsnn.ExecutionInstance()\n",
    "\n",
    "            linear = Synapse(\n",
    "                in_features=784,\n",
    "                out_features=64,\n",
    "                experiment=self.exp1,\n",
    "                execution_instance=execution_instance,\n",
    "                cap=1. if mock else 63. / weight_scale_hidden,\n",
    "                weight_exp_rolloff=weight_exp_rolloff,\n",
    "                use_quantization=use_quantization,\n",
    "                transform=partial(\n",
    "                    weight_transforms.linear_saturating,\n",
    "                    scale=weight_scale_hidden))\n",
    "            self.linear_hidden.append(linear)\n",
    "            # attach module to snn instance\n",
    "            setattr(self, f\"linear_hidden_{i}\", linear)\n",
    "\n",
    "            neuron = hxsnn.Neuron(\n",
    "                size=64,\n",
    "                experiment=self.exp1,\n",
    "                execution_instance=execution_instance,\n",
    "                alpha=alpha,\n",
    "                trace_scale=trace_scale_hidden,\n",
    "                cadc_time_shift=-1,\n",
    "                shift_cadc_to_first=True,\n",
    "                neuron_structure=morph_hidden,\n",
    "                **lif_params)\n",
    "            self.neurons_hidden.append(neuron)\n",
    "            # attach module to snn instance\n",
    "            setattr(self, f\"neuron_hidden_{i}\", neuron)\n",
    "\n",
    "        # initialize weights\n",
    "        for linear in self.linear_hidden:\n",
    "            torch.nn.init.normal_(linear.weight.data, *weight_init_hidden)\n",
    "\n",
    "        # Output layer\n",
    "        # We use second experiment instance to place software-only dropout\n",
    "        # layer in-between\n",
    "        self.exp2 = hxsnn.Experiment(mock=mock, dt=dt)\n",
    "        self.exp2.inter_batch_entry_wait = 125 * 50  # us\n",
    "\n",
    "        self.linear_output = Synapse(\n",
    "            in_features=256,\n",
    "            out_features=10,\n",
    "            experiment=self.exp2,\n",
    "            cap=1. if mock else 63. / weight_scale_output,\n",
    "            weight_exp_rolloff=weight_exp_rolloff,\n",
    "            use_quantization=use_quantization,\n",
    "            transform=partial(\n",
    "                weight_transforms.linear_saturating,\n",
    "                scale=weight_scale_output))\n",
    "\n",
    "        torch.nn.init.normal_(\n",
    "            self.linear_output.weight.data, *weight_init_output)\n",
    "\n",
    "        self.neuron_output = hxsnn.ReadoutNeuron(\n",
    "            size=10,\n",
    "            experiment=self.exp2,\n",
    "            trace_scale=trace_scale_output,\n",
    "            cadc_time_shift=-1,\n",
    "            shift_cadc_to_first=True,\n",
    "            neuron_structure=morph_output,\n",
    "            **li_params)\n",
    "\n",
    "        # NOTE: We can use PyTorch's dropout since we execute hidden and\n",
    "        #       output layer seperately any simply can \"dropout\" neurons in\n",
    "        #       software.\n",
    "        self.dropout = torch.nn.Dropout(dropout_hidden)\n",
    "\n",
    "        # device\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "        # placeholder for (hidden) spikes\n",
    "        self.spikes = []\n",
    "\n",
    "        # placeholder for current encoded inputs and output traces\n",
    "        self.encoded_input = None\n",
    "        self.traces = []\n",
    "\n",
    "    def forward(self, spikes: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform a forward path.\n",
    "\n",
    "        :param spikes: PyTorch tensor holding spikes as input.\n",
    "\n",
    "        :return: Returns the output of the network, i.e. membrane traces of\n",
    "            the readout neurons.\n",
    "        \"\"\"\n",
    "        # clear spike list and traces list for each iteration\n",
    "        self.spikes = []\n",
    "        self.traces = []\n",
    "\n",
    "        # Spike input\n",
    "        # We reshape from (time, batch, x, y) to (time, batch, x*y)\n",
    "        inputs = spikes.view(spikes.shape[0], spikes.shape[1], -1)\n",
    "\n",
    "        # Forward\n",
    "        syn_handles = []\n",
    "        lif_handles = []\n",
    "        syn_handles = [\n",
    "            lin(hxsnn.NeuronHandle(inputs)) for lin in self.linear_hidden]\n",
    "        lif_handles = [\n",
    "            nrn(syn_handle) for (nrn, syn_handle) in zip(\n",
    "                self.neurons_hidden, syn_handles)]\n",
    "\n",
    "        # runtime 2 additional time steps for buffer\n",
    "        hxsnn.run(self.exp1, inputs.shape[0] + 2)\n",
    "\n",
    "        hidden_traces = torch.cat(\n",
    "            [lif_handles[i].membrane_cadc for i in range(4)], 2)\n",
    "        hidden_spikes = torch.cat(\n",
    "            [lif_handles[i].spikes for i in range(4)], 2)\n",
    "\n",
    "        # dropout after hidden layer\n",
    "        hidden_spikes = self.dropout(hidden_spikes)\n",
    "\n",
    "        # output\n",
    "        hidden_handle = hxsnn.NeuronHandle(hidden_spikes)\n",
    "        w_hidden = self.linear_output(hidden_handle)\n",
    "        output = self.neuron_output(w_hidden)\n",
    "\n",
    "        # runtime 2 additional time steps for buffer\n",
    "        hxsnn.run(self.exp2, inputs.shape[0] + 2)\n",
    "\n",
    "        self.traces = [hidden_traces] + [output.membrane_cadc]\n",
    "        self.spikes = [hidden_spikes]\n",
    "\n",
    "        return self.traces[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a3246",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "\n",
    "    \"\"\" Complete model with encoder, network (snn) and decoder \"\"\"\n",
    "\n",
    "    def __init__(self, encoder: torch.nn.Module,\n",
    "                 network: torch.nn.Module,\n",
    "                 decoder: torch.nn.Module) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the model by assigning encoder, network and decoder\n",
    "\n",
    "        :param encoder: Module to encode input data\n",
    "        :param network: Network module containing layers and\n",
    "            parameters / weights\n",
    "        :param decoder: Module to decode network output\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.network = network\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Perform forward pass through whole model, i.e.\n",
    "        data -> encoder -> network -> decoder -> output\n",
    "\n",
    "        :param inputs: tensor input data\n",
    "\n",
    "        :returns: Returns tensor output\n",
    "        \"\"\"\n",
    "        spikes = self.encoder(inputs)\n",
    "        traces = self.network(spikes)\n",
    "        self.scores = self.decoder(traces).clone()\n",
    "\n",
    "        return self.scores\n",
    "\n",
    "    def regularize(self, reg_readout: float = 0, reg_bursts: float = 0,\n",
    "                   reg_w_hidden: float = 0, reg_w_output: float = 0,\n",
    "                   exponent: int = 2) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute regularization loss for spiking activity, magnitude of\n",
    "        weights and magnitude of max-over-time values.\n",
    "\n",
    "        :param reg_bursts: prefactor of burst / hidden spike regulaization\n",
    "        :param reg_weights_hidden: prefactor of hidden weight regularization\n",
    "        :param reg_weights_output: prefactor of output weight regularization\n",
    "        :param exponent: exponent in regularization terms\n",
    "\n",
    "        :returns: Returns regularization terms in a tensor and their sum\n",
    "        \"\"\"\n",
    "        reg = torch.tensor(0., device=self.scores.device)\n",
    "\n",
    "        # Reg readout\n",
    "        reg_scores = reg_readout * torch.mean(self.scores ** exponent)\n",
    "        reg += reg_scores\n",
    "\n",
    "        # bursts (hidden spikes) regularization\n",
    "        reg_spikes = torch.tensor(0., device=self.scores.device)\n",
    "        for spikes in self.network.spikes:\n",
    "            reg_spikes += reg_bursts * torch.mean(\n",
    "                torch.sum(spikes, dim=0) ** exponent)\n",
    "        reg += reg_spikes\n",
    "\n",
    "        # weight regularization\n",
    "        reg_weight = torch.tensor(0., device=self.scores.device)\n",
    "        for linear in self.network.linear_hidden:\n",
    "            reg_weight += reg_w_hidden * \\\n",
    "                torch.mean(linear.weight ** exponent)\n",
    "\n",
    "        reg_weight += reg_w_output * torch.mean(\n",
    "            self.network.linear_output.weight ** exponent)\n",
    "\n",
    "        reg += reg_weight\n",
    "\n",
    "        return reg, torch.tensor(\n",
    "            [reg_scores.item(), reg_spikes.item(), reg_weight.item()])\n",
    "\n",
    "    def get_rate(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates (and returns) the rate at which neurons fire per input\n",
    "        and per neuron.\n",
    "\n",
    "        :returns: Firing rate per neuron and input for whole network.\n",
    "        \"\"\"\n",
    "        rate = torch.tensor(0., device=self.network.spikes[0].device)\n",
    "        for spikes in self.network.spikes:\n",
    "            rate += spikes.sum(0).mean()\n",
    "        return rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b29e8e1",
   "metadata": {},
   "source": [
    "## Calibrations and Parameters\n",
    "\n",
    "Before we set up the training functions for our model, lets take a step back and realize that the neuron parameters that are set in the model above have to be calibrated on hardware - if we are not using the mock-mode.\n",
    "We will just have to set some parameters and the BSS-2 system will be calibrated implicitly.\n",
    "Changing neuron parameters like the leak or threshold potential requires recalibration which takes some minutes.\n",
    "Parameterizing neurons on BSS-2 is discussed in more detail in the tutorials [BrainScaleS-2 single neuron experiments](ts_00-single_neuron.ipynb) and [hxtorch.snn Introduction](ts_11-hxtorch_snn_intro.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923a134b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Neuron parameters\n",
    "tau_syn = 5.7e-6\n",
    "tau_mem = 6e-6\n",
    "leak = 80\n",
    "reset = 80\n",
    "threshold = 120\n",
    "alpha = 50\n",
    "dt = 1e-6\n",
    "\n",
    "# Simulation\n",
    "mock = False\n",
    "weight_scale = 1.\n",
    "trace_scale = 1.\n",
    "cap = 1.6\n",
    "\n",
    "# Regularization parameters\n",
    "reg_bursts = 0.0025\n",
    "reg_weights_hidden = 0.0033\n",
    "reg_readout = 1.6e-4\n",
    "reg_weights_output = 0.0033\n",
    "reg_gamma = 0.985\n",
    "reg_step_size = 1\n",
    "\n",
    "# Training parameters\n",
    "epochs = 3\n",
    "lr = 0.002\n",
    "dropout = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cea484",
   "metadata": {},
   "source": [
    "You might also return to these parameters later and choose different regularization values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fc99f",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "We will now set up the training and testing methods for any model that we might choose.\n",
    "The loss function will consist of the cross-entropy loss as well as the regularization terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0549eb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def run_epoch(model: torch.nn.Module, loader: DataLoader,\n",
    "              optimizer: torch.optim.Optimizer, epoch: int, train: bool,\n",
    "              update_func: Callable) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Perform training or testing for one epoch.\n",
    "\n",
    "    :param model: The model to train/test.\n",
    "    :param loader: Pytorch DataLoader instance providing training/testing\n",
    "        data.\n",
    "    :param optimizer: The optimizer used for weight optimization.\n",
    "    :param epoch: Current epoch for logging.\n",
    "    :param train: Bool indicating whether we train or evaluate the model.\n",
    "    :update_func: A function to track data for plotting.\n",
    "\n",
    "    :returns: Tuple (loss, accuracy, mean rate)\n",
    "    \"\"\"\n",
    "    # define loss function\n",
    "    loss_func = torch.nn.functional.nll_loss\n",
    "\n",
    "    model.train(mode=train) # sets model in training / eval mode\n",
    "\n",
    "    dev = model.network.device\n",
    "    total_loss, total_reg_loss, total_acc, total_rate = [], [], [], []\n",
    "\n",
    "    for data, target in loader:\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        scores = model(data.to(dev))\n",
    "\n",
    "        # compute regularization loss and add up\n",
    "        reg_loss_b, _ = model.regularize(\n",
    "            reg_readout, reg_bursts * reg_gamma **\\\n",
    "                            ((int)((epoch - 1) / reg_step_size)),\n",
    "            reg_weights_hidden, reg_weights_output, exponent=4)\n",
    "\n",
    "        total_reg_loss.append(reg_loss_b.detach().flatten())\n",
    "\n",
    "        # compute total loss\n",
    "        loss = loss_func(scores, target.to(dev)) + reg_loss_b\n",
    "        total_loss.append(loss.detach().flatten())\n",
    "\n",
    "        if train: # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Train accuracy\n",
    "        pred = scores.cpu().argmax(dim=1)\n",
    "        acc = pred.eq(target.view_as(pred)).float()\n",
    "        total_acc.append(acc.detach().flatten())\n",
    "\n",
    "        # Firing rates\n",
    "        rate = model.get_rate()\n",
    "        total_rate.append(rate.detach().flatten())\n",
    "\n",
    "    total_loss = torch.cat(total_loss).mean().cpu()\n",
    "    total_acc = torch.cat(total_acc).mean().cpu()\n",
    "    total_rate = torch.cat(total_rate).mean().cpu()\n",
    "    total_reg_loss = torch.cat(total_reg_loss).mean().cpu()\n",
    "\n",
    "    # Update data for plotting\n",
    "    update_func(loss=total_loss, acc=total_acc, rate=total_rate)\n",
    "\n",
    "    print(f\"Train: {train}, Epoch {epoch}, Loss {total_loss:.4f}, Accuracy {total_acc:.4f}\")\n",
    "\n",
    "    return total_loss, total_acc, total_rate, total_reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09c095",
   "metadata": {},
   "source": [
    "## Final Setup And The Training Loop\n",
    "\n",
    "We can now approach the final setup for our training.\n",
    "For the mapping between the hardware measurements and the software simulation, we will initiate a calibration and measure the scaling of the weights and traces.\n",
    "This is necessary as we assume `v_th = 1` and `leak, reset = 0` in software.\n",
    "To ensure a correspondance between the gradient in software and the neural dynamics on hardware, a transformation of the software weights to hardware weights and a transformation of membrane observables on hardware to membrane traces in software need to be found (therefore: `get_weight_scaling(...)`).\n",
    "The mapping between hardware dynamics and the dynamics assumed for computing gradients in explained and visualized in [hxtorch.snn Introduction](ts_11-hxtorch_snn_intro.ipynb).\n",
    "\n",
    "The calibration might take a while so feel free to read on until it is finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8f10d3",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from _static.tutorial.measure_mock_scaling import get_weight_scaling, get_trace_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a5fad6",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "params_hidden = {\n",
    "    \"tau_mem\": tau_mem,\n",
    "    \"tau_syn\": tau_syn,\n",
    "    \"i_synin_gm\": 800,\n",
    "    \"synapse_dac_bias\": 850,\n",
    "    \"leak\": hxsnn.MixedHXModelParameter(0., leak),\n",
    "    \"reset\": hxsnn.MixedHXModelParameter(0., reset),\n",
    "    \"threshold\": hxsnn.MixedHXModelParameter(1., threshold),\n",
    "    \"refractory_time\": 1e-6}\n",
    "\n",
    "lif_morph = hxsnn.morphology.SingleCompartmentNeuron(\n",
    "    size=8, expand_horizontally=False)\n",
    "\n",
    "params_output = {\n",
    "    \"tau_mem\": tau_mem,\n",
    "    \"tau_syn\": tau_syn,\n",
    "    \"i_synin_gm\": 400,\n",
    "    \"synapse_dac_bias\": 700,\n",
    "    \"leak\": hxsnn.MixedHXModelParameter(0., leak),\n",
    "    \"reset\": hxsnn.MixedHXModelParameter(0., reset),\n",
    "    \"threshold\": hxsnn.MixedHXModelParameter(1., threshold)}\n",
    "\n",
    "li_morph = hxsnn.morphology.SingleCompartmentNeuron(\n",
    "    size=2, expand_horizontally=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f48116",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "weight_scale_hidden, weight_scale_output = 1., 1.\n",
    "trace_scale_hidden, trace_scale_output = 1., 1.\n",
    "\n",
    "# Create calibrations\n",
    "if not mock:\n",
    "    # HW - SW membrane scaling\n",
    "    trace_scale_hidden = get_trace_scaling(lif_morph, params_hidden)\n",
    "    print(f\"Trace scaling HW -> SW, hidden layer: {trace_scale_hidden}\")\n",
    "    trace_scale_output = get_trace_scaling(li_morph, params_output)\n",
    "    print(f\"Trace scaling HW -> SW, output layer: {trace_scale_output}\")\n",
    "\n",
    "    # HW - SW weight factor for hidden and output neurons\n",
    "    weight_scale_hidden = get_weight_scaling(params_hidden, 10, lif_morph)\n",
    "    print(f\"Weight scaling SW -> HW, hidden layer: {weight_scale_hidden}\")\n",
    "    weight_scale_output = get_weight_scaling(params_output, 10, li_morph)\n",
    "    print(f\"Weight scaling SW -> HW, output layer: {weight_scale_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81242d34",
   "metadata": {},
   "source": [
    "## The Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5349c91f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import ipywidgets as w\n",
    "\n",
    "from _static.tutorial.partitioning_plots import plot_training\n",
    "\n",
    "model = Model(\n",
    "    partial(ttfs_encode, sequence_length=30),\n",
    "    SNN(lif_params=params_hidden,\n",
    "        li_params=params_output,\n",
    "        mock=mock,\n",
    "        dt=dt,\n",
    "        weight_init_hidden=(-0.05, 0.2),\n",
    "        weight_init_output=(0.01, 0.2),\n",
    "        weight_scale_hidden=weight_scale_hidden,\n",
    "        weight_scale_output=weight_scale_output,\n",
    "        trace_scale_hidden=trace_scale_hidden,\n",
    "        trace_scale_output=trace_scale_output,\n",
    "        dropout_hidden=dropout,\n",
    "        device=dev),\n",
    "    partial(decode, trace_scaling=3.))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=1, gamma=0.97)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f0cf4",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f141dc83",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# initialize hardware\n",
    "hxtorch.init_hardware()\n",
    "hxtorch.logger.set_loglevel(\n",
    "    hxtorch.logger.get(\"grenade\"), hxtorch.logger.LogLevel.ERROR)\n",
    "\n",
    "# plotting during training\n",
    "update_plot, update_train_data, update_test_data = plot_training(epochs)\n",
    "plt.close()\n",
    "output = w.Output()\n",
    "display(output)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    loss_train, acc_train, rate_train, regs_train = run_epoch(\n",
    "        model, train_loader, optimizer, epoch, True, update_train_data)\n",
    "    loss_test, acc_test, rate_test, regs_test = run_epoch(\n",
    "        model, test_loader, optimizer, epoch, False, update_test_data)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Refresh plot\n",
    "    output.clear_output(wait=True)\n",
    "    with output:\n",
    "        update_plot()\n",
    "\n",
    "hxtorch.release_hardware()"
   ]
  }
 ],
 "metadata": {
  "date": 1741779497.4902296,
  "filename": "ts_12-network_partitioning.rst",
  "kernelspec": {
   "display_name": "EBRAINS-experimental",
   "language": "python3",
   "name": "ebrains-experimental"
  },
  "title": "Partitioning of Feedforward SNNs"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
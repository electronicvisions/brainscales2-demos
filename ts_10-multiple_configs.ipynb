{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8714a376",
   "metadata": {},
   "source": [
    "# Demonstration of multiple chip-reconfigurations during an experiment\n",
    "\n",
    "This modification of the [plasticity experiment](ts_02-plasticity_rate_coding.ipynb) showcases the\n",
    "dynamic reconfiguration of the chip by using the new append functionality of pynn.brainscales. This\n",
    "example only changes synaptic weights during the experiment, but any arbitrary changes to the chip\n",
    "configuration can be applied this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8bf3c",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pynn_brainscales.brainscales2 as pynn\n",
    "from dlens_vx_v3 import hal\n",
    "\n",
    "# setup shared connection to hardware\n",
    "from _static.common.helpers import setup_hardware_client\n",
    "setup_hardware_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79f287c",
   "metadata": {},
   "source": [
    "## The Experiment\n",
    "\n",
    "The goal of this experiment is to take a picture as an input, adjust the weights of some specific\n",
    "synapses to match the pixel values, and send spike-trains through these synapses, so that the\n",
    "according neurons can detect these pixel values again and we can use the measured data in the end,\n",
    "to recreate the image.\n",
    "For this example, we used the 64 x 64 Pixel “visions.png” image:\n",
    "\n",
    "<img src=\"_static/tutorial/visions.png\" style=\"width:30%;\" align=\"center\">\n",
    "\n",
    "Therefore we read in the pixel values of the image as the first step of our program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8a21e",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def read_image(path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Read image from file and scale it to the weight range.\n",
    "    :param path: Path to image file\n",
    "    :return: Image data as numpy array normalised to hardware weight range\n",
    "    \"\"\"\n",
    "    image = np.asarray(plt.imread(path))\n",
    "    # Scale to weight range [0, 63]\n",
    "    image = image / image.max() * hal.SynapseWeightQuad.Value.max\n",
    "    return np.flipud(image).T\n",
    "\n",
    "# Read image into 2d numpy array\n",
    "image = read_image(join(\"_static\", \"tutorial\", \"visions.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc108701",
   "metadata": {},
   "source": [
    "## Setup of the Experiment\n",
    "\n",
    "We now have a 2d numpy array `image` that has the (scalar) pixel values of our black-and-white\n",
    "image. Our network consists of two populations: An input population of one neuron, that feeds the\n",
    "input spikes into the synapse array and a recording population of 64 neurons.\n",
    "The projection projects the signal of the input neuron with an `AllToAllConnector` to all 64\n",
    "recording neurons across individual synapses, the weights of which can be modified according to the\n",
    "pixel values of the picture throughout the experiment. The input neuron will send 100 spikes onto\n",
    "the chip, linearly spaced in time over the duration of our runtime, which is 10ms.\n",
    "To ensure, that our recording neurons spike when receiving input spikes, we pass the argument\n",
    "`enable_neuron_bypass=True` when setting up our simulator object with `pynn.setup()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec0d34",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "pynn.setup(enable_neuron_bypass=True)\n",
    "\n",
    "runtime = 10  # runtime per configuration in ms\n",
    "n_spikes = 100\n",
    "spikes = np.linspace(0, runtime, n_spikes)\n",
    "\n",
    "input_population = pynn.Population(1, pynn.cells.SpikeSourceArray(spike_times = spikes))\n",
    "recording_population = pynn.Population(64, pynn.cells.HXNeuron())\n",
    "recording_population.record('spikes')\n",
    "\n",
    "synapse = pynn.standardmodels.synapses.StaticSynapse(weight=32)\n",
    "projection = pynn.Projection(input_population,\n",
    "                recording_population,\n",
    "                pynn.AllToAllConnector(),\n",
    "                receptor_type=\"excitatory\",\n",
    "                synapse_type=synapse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb087415",
   "metadata": {},
   "source": [
    "## Reconfiguration and Execution\n",
    "\n",
    "We want to reconfigure our projection every 10ms to represent the weights of the next row of our\n",
    "image. In order to do this, we iterate over all rows of our image and set the synapse weights\n",
    "accordingly inside the loop followed by a call of `pynn.run()` with the append command, which\n",
    "appends a new snippet with the current configuration and a duration of `runtime` to the\n",
    "experiment. After we have scheduled our complete experiment, we call `pynn.run()` with the\n",
    "execute command to trigger the execution of the experiment on hardware. In the performed hardware\n",
    "run, all our staged configurations are being executed one after another for the given runtime each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42373a95",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    projection.set(weight=image[i])\n",
    "    # Append a snippet of duration 'runtime' with the currently described network configuration\n",
    "    # to the experiment\n",
    "    pynn.run(runtime, pynn.RunCommand.APPEND)\n",
    "\n",
    "# Trigger the execution of a hardware run without scheduling another snippet\n",
    "pynn.run(None, pynn.RunCommand.EXECUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edce7e",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "We firstly retrieve all recorded spiketrains from the `recording_population`. These are 64*64 in\n",
    "total, because we get one per neuron per snippet. However, all spiketrains of each neuron, according\n",
    "to the different realtime snippets, are ordered by the number of the realtime snippets, i.e. by\n",
    "time.\n",
    "In order to plot our result, we need one continuous spiketrain per neuron. Therefore, we need to\n",
    "filter the returned list of spiketrains by the neuron index, i.e. the cell id and concatenate the\n",
    "times of all spiketrains belonging to the same neuron.\n",
    "By showing now the times, where we a spike was recorded for each neuron, we should get the image\n",
    "from the beginning again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a1a04",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "#read out results\n",
    "spiketrains = recording_population.get_data('spikes').segments[0].spiketrains\n",
    "spiketrains_concatenated = [ [] for _ in range(64) ]\n",
    "for spiketrain in spiketrains:\n",
    "    spiketrains_concatenated[spiketrain.annotations[\"source_id\"]-1].extend(spiketrain.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8751cb",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "#plot results\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(4, 4)\n",
    "\n",
    "plt.eventplot(spiketrains_concatenated, color='#990000')\n",
    "plt.xlim(0,640)\n",
    "plt.ylim(0,63)\n",
    "plt.xlabel(\"time [ms]\")\n",
    "plt.ylabel(\"neuron index\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4952e",
   "metadata": {},
   "source": [
    "We see a replicated version of the original image encoded in the time evolution of\n",
    "the neurons’ firing rates."
   ]
  }
 ],
 "metadata": {
  "date": 1727430819.3152685,
  "filename": "ts_10-multiple_configs.rst",
  "kernelspec": {
   "display_name": "EBRAINS-experimental",
   "language": "python",
   "name": "ebrains-experimental"
  },
  "title": "Demonstration of multiple chip-reconfigurations during an experiment"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
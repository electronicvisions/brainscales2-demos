{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3f816dc",
   "metadata": {},
   "source": [
    "# How to use Genetic Algorithms to automatically parameterize BrainScaleS-2\n",
    "\n",
    "In simulations of compartmental neurons it is a non-trivial task to find a suitable parameterization of the model [[VB99]](#vb99), such that it matches observations from real neurons, like found in [[BLL01]](#bll01).\n",
    "In this tutorial, we’ll present an approach using genetic algorithms to automate this parameterization.\n",
    "The presented approach can be used to configure the analog neurons of BrainScaleS-2 such that they can replicate experimental data.\n",
    "\n",
    "In particular, we will\n",
    "\n",
    "- create a linear chain of compartments using PyNN  \n",
    "- visualize the attenuation of an excitatory postsynaptic potential\n",
    "  (EPSP) along the compartment chain  \n",
    "- investigate how the leak conductance and the inter-compartment\n",
    "  conductance influence the attenuation of the EPSP  \n",
    "- use genetic algorithms to automatically find appropriate parameters\n",
    "  for the neuron circuits to replicate a given observation  \n",
    "\n",
    "\n",
    "To execute experiments on BrainScaleS-2 we use a microscheduler for whom we first have to set some environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96031b05",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from _static.common.helpers import setup_hardware_client\n",
    "setup_hardware_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35870c77",
   "metadata": {},
   "source": [
    "We’ll also configure matplotlib and import some tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef5487",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from typing import Container, List, Tuple, Sequence, Union\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import quantities as pq\n",
    "import neo\n",
    "import ipywidgets as widget\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as mplstyle\n",
    "from scipy.optimize import curve_fit\n",
    "import deap\n",
    "from deap import algorithms, base, creator, tools\n",
    "from tqdm.contrib.itertools import product\n",
    "\n",
    "import pynn_brainscales.brainscales2 as pynn\n",
    "\n",
    "# Use default style such that colors in plots and texts match\n",
    "mplstyle.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4634d5",
   "metadata": {},
   "source": [
    "As a next preparation step, we load the default calibration, which is generated for every BrainScaleS-2 chip every night.\n",
    "It is saved in a variable such that we can use it later when we define our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e295a02",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from _static.common.helpers import get_nightly_calibration\n",
    "calib = get_nightly_calibration()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e577498",
   "metadata": {},
   "source": [
    "## Constructing the Compartment Chain in PyNN\n",
    "\n",
    "In the tutorial [Multicompartmental Neurons](ts_03-multicompartment.ipynb), the concept of multi-compartment neurons was introduced, which are spatially structured neurons.\n",
    "Here we will continue with the compartment chain experiments.\n",
    "Therefore, we first create a compartment chain class, summarizing the experiments of the [Multicompartmental Neurons](ts_03-multicompartment.ipynb) tutorial and extending it with further functionality for the experiments of this tutorial.\n",
    "Upon initialization the class creates a compartment chain of provided length.\n",
    "Additionally, the first compartment is connected to an external population (refer to [figure 1](#figure-1)) that will spike at a specified point in time.\n",
    "This causes an EPSP that travels along the chain.\n",
    "\n",
    "\n",
    "<a id='figure-1'></a>\n",
    "<img src=\"_static/tutorial/ga_chain_external_pop.png\" style=\"width:50%;\">\n",
    "\n",
    "Figure 1: Compartment chain of length 5 and external population connecting to the first compartment.  \n",
    "The class functions are summarized in the following:\n",
    "\n",
    "- `create_input_projection`: Generates an external population of size `inputs` and connects it to the first compartment.\n",
    "  All neurons of the external population will spike simultaneously, introducing an EPSP in the compartment chain.  \n",
    "- `set_conductances`: Sets the leak and inter-compartment conductance to the provided values.  \n",
    "- `record_membrane`: Records the experiment, i.e. the EPSP traveling along the compartment chain.  \n",
    "- `extract_psp_amplitudes`: Extracts the amplitudes of the EPSP in each compartment.  \n",
    "- `fit_length_constant`: Fit an exponential function to the EPSP amplitudes.  \n",
    "- `run_and_eval`: This function executes the experiment and returns the fit parameters and the amplitudes.  \n",
    "- `evaluate`: This function calls `run_and_eval` and compares the extracted length constant to a target.  \n",
    "- `fitfunc`: Defines an exponential function of the form $ f(x) = A \\cdot \\exp\\left(-\\frac{x}{\\lambda}\\right) + c $.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728dd76",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class CompartmentChain():\n",
    "    '''\n",
    "    Creates a compartment chain of provided length upon initialization and\n",
    "    supplies further functionalities to run and evaluate experiments.\n",
    "\n",
    "    :ivar length: Lenght of the compartment chain.\n",
    "    :ivar compartments: Compartments of the chain.\n",
    "    :ivar runtime: Experiment runtime in ms.\n",
    "    :ivar spike_time: Time of input spike.\n",
    "    :ivar projection: Projections between external population and first\n",
    "        compartment of the chain.\n",
    "    '''\n",
    "    def __init__(self, length: int, weight: int = 63):\n",
    "        self.length = length\n",
    "        self.compartments = self._create_chain()\n",
    "        self.runtime = 0.15 * pq.ms  # (hw)\n",
    "        self.spike_time = self.runtime / 2  # (hw)\n",
    "        self.projection = self.create_input_projection()\n",
    "        self.projection.set(weight=weight)\n",
    "\n",
    "    def _create_chain(self) -> List[pynn.PopulationView]:\n",
    "        '''\n",
    "        Create linear compartment chain.\n",
    "\n",
    "        A compartment will be constructed out of two neuron circuits.\n",
    "        Thereby, one neuron circuit will handle the parameters of a\n",
    "        compartment.\n",
    "\n",
    "        :returns: List containing every compartment of the chain.\n",
    "        '''\n",
    "        pop = pynn.Population(self.length * 2, pynn.cells.HXNeuron())\n",
    "\n",
    "        # Combine two neuron circuits to one compartment; \"disable\" second\n",
    "        # neuron circuit\n",
    "        pynn.PopulationView(pop, np.arange(0, 2 * self.length, 2)).set(\n",
    "            multicompartment_connect_right=True,\n",
    "            leak_i_bias=0,\n",
    "            leak_enable_division=True,\n",
    "            membrane_capacitance_capacitance=0)\n",
    "\n",
    "        # Enable direct connection to somatic line for even neuron circuits\n",
    "        # (don't connect first neuron circuit)\n",
    "        pynn.PopulationView(pop, np.arange(2, 2 * self.length, 2)).set(\n",
    "            multicompartment_connect_soma=True)\n",
    "\n",
    "        # Connect resistor to somatic line and close connection to the right\n",
    "        # for uneven circuits (don't connect last neuron circuit)\n",
    "        # Note: We enable both leak division and inter-compartment\n",
    "        # conductance division here since it results in larger length\n",
    "        # constants. This allows the EPSP to travel further down the chain\n",
    "        # and is chosen for the sake of this tutorial. Real neurons might\n",
    "        # exhibit different dynamical properties which might need other\n",
    "        # settings for those two parameters.\n",
    "        pynn.PopulationView(pop, np.arange(1, 2 * self.length - 1, 2)).set(\n",
    "            multicompartment_enable_conductance=True,\n",
    "            multicompartment_i_bias_nmda=600,\n",
    "            multicompartment_connect_soma_right=True,\n",
    "            multicompartment_enable_conductance_division=True,\n",
    "            leak_enable_division=True)\n",
    "\n",
    "        # Disable spiking\n",
    "        pop.set(threshold_enable=False)\n",
    "\n",
    "        # Every uneven neuron circuit controls the capacitance, resistance,\n",
    "        # leak, ... of a single compartment. Return views on these circuits\n",
    "        # as compartments\n",
    "        return [pynn.PopulationView(pop, [n]) for n in\n",
    "                range(1, 2 * self.length, 2)]\n",
    "\n",
    "    def create_input_projection(self, inputs: int = 5) -> pynn.Projection:\n",
    "        '''\n",
    "        Set projection from an external population of size `inputs`, which\n",
    "        elicits a spike at the time defined by spike_time, to the first\n",
    "        compartment.\n",
    "\n",
    "        :param inputs: Size of external population.\n",
    "        :returns: Projection from input population to first compartment.\n",
    "        '''\n",
    "        # Inject stimulus in first compartment\n",
    "        pop_in = pynn.Population(inputs, pynn.cells.SpikeSourceArray(\n",
    "            spike_times=[float(self.spike_time.rescale(pq.ms))]))\n",
    "\n",
    "        # Note: the weight will be set later\n",
    "        synapse_type = pynn.standardmodels.synapses.StaticSynapse()\n",
    "        return pynn.Projection(\n",
    "            pop_in, self.compartments[0], pynn.AllToAllConnector(),\n",
    "            synapse_type=synapse_type)\n",
    "\n",
    "    def set_conductances(self, leak_conductance: int,\n",
    "                         inter_compartment_conductance: int) -> None:\n",
    "        '''\n",
    "        Set leak and inter-compartment conductance of the chain.\n",
    "\n",
    "        Both the leak_conductance and the inter_compartment_conductance\n",
    "        have a parameter range from 0 to 1022.\n",
    "\n",
    "        :param leak_conductance: Leak conductance that will be set.\n",
    "        :param inter_compartment_conductance: Inter-compartment conductance\n",
    "            that will be set.\n",
    "        '''\n",
    "        for comp in self.compartments:\n",
    "            self.g_leak = leak_conductance\n",
    "            self.g_ic = inter_compartment_conductance\n",
    "            comp.set(\n",
    "                multicompartment_i_bias_nmda=inter_compartment_conductance)\n",
    "            comp.set(leak_i_bias=leak_conductance)\n",
    "\n",
    "    def record_membrane(self) -> List[neo.IrregularlySampledSignal]:\n",
    "        '''\n",
    "        Record the membrane of each compartment of the chain.\n",
    "\n",
    "        The experiment is repeated `self.length` times since the MADC can only\n",
    "        record one neuron circuit's membrane at a time.\n",
    "\n",
    "        :returns: Membrane traces of each compartment.\n",
    "        '''\n",
    "        # Run on hardware and record membrane potentials\n",
    "        membrane_traces = []\n",
    "        for n_comp, comp in enumerate(self.compartments):\n",
    "            comp.record(['v'])\n",
    "\n",
    "            pynn.run(self.runtime.rescale(pq.ms).magnitude)\n",
    "            pynn.reset()\n",
    "\n",
    "            sig = comp.get_data().segments[-1].irregularlysampledsignals[0]\n",
    "            sig.annotate(compartment=n_comp, spike_time=self.spike_time)\n",
    "\n",
    "            membrane_traces.append(sig)\n",
    "\n",
    "            comp.record(None)\n",
    "\n",
    "        return membrane_traces\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_psp_amplitudes(\n",
    "            membrane_traces: List[neo.IrregularlySampledSignal]) -> np.ndarray:\n",
    "        '''\n",
    "        Extract the PSP amplitudes from membrane recordings.\n",
    "\n",
    "        :param traces: Analog signal for each compartment in the chain.\n",
    "        :returns: Amplitudes of PSP (difference between maximum and baseline).\n",
    "            The amplitudes are calculated for each compartment.\n",
    "        '''\n",
    "        amplitudes = []\n",
    "        for sig in membrane_traces:\n",
    "            spike_time = sig.annotations['spike_time'].rescale(pq.ms)\n",
    "\n",
    "            # use membrane voltage before first spike as baseline\n",
    "            baseline = sig.time_slice(sig.t_start, spike_time).mean()\n",
    "\n",
    "            amplitudes.append(sig.max() - baseline)\n",
    "        return np.asarray(amplitudes)\n",
    "\n",
    "    @classmethod\n",
    "    def fit_length_constant(\n",
    "            cls, amplitudes: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        '''\n",
    "        Fit an exponential decay to the PSP amplitudes in the compartments.\n",
    "\n",
    "        :param amplitudes: Amplitudes of the EPSP for each compartment in the\n",
    "            chain.\n",
    "        :returns: Fit parameters and covariance matrix for the fit to the\n",
    "            exponential.\n",
    "        '''\n",
    "        norm_amp = amplitudes / amplitudes[0]\n",
    "        compartments = np.arange(len(amplitudes))\n",
    "\n",
    "        # initial guess for fit parameters\n",
    "        guessed_lambda = np.argmin(np.abs(norm_amp - 1 / np.e))\n",
    "        p_0 = {'lambda_': guessed_lambda, 'offset': norm_amp[-1],\n",
    "               'scale': norm_amp[0] - norm_amp[-1]}\n",
    "        bounds = {'lambda_': [0, np.inf],\n",
    "                  'offset': p_0['offset'] + np.array([-1, 1]),\n",
    "                  'scale': [0, np.inf]}\n",
    "\n",
    "        popt, pcov = curve_fit(\n",
    "            cls.fitfunc, compartments, norm_amp,\n",
    "            p0=[p_0['lambda_'], p_0['offset'], p_0['lambda_']],\n",
    "            bounds=([bounds['lambda_'][0], bounds['offset'][0],\n",
    "                     bounds['scale'][0]],\n",
    "                    [bounds['lambda_'][1], bounds['offset'][1],\n",
    "                     bounds['scale'][1]]))\n",
    "\n",
    "        return popt, pcov\n",
    "\n",
    "    def run_and_eval(self, leak_conductance: int,\n",
    "                     inter_compartment_conductance: int) -> Tuple[\n",
    "            np.ndarray, np.ndarray, np.ndarray]:\n",
    "        '''\n",
    "        Executes the experiment and fits an exponential to the maximum\n",
    "        amplitude of the EPSP in each compartment.\n",
    "\n",
    "        The fit parameters and the extracted amplitudes are then returned.\n",
    "\n",
    "        :param leak_conductance: Leak conductance that will be set.\n",
    "        :param inter_compartment_conductance: Inter-compartment conductance\n",
    "            that will be set.\n",
    "        :returns: Fit parameters, estimated covariance of fit parameters\n",
    "            and amplitudes of the EPSP in each compartment.\n",
    "        '''\n",
    "\n",
    "        self.set_conductances(\n",
    "            leak_conductance=leak_conductance,\n",
    "            inter_compartment_conductance=inter_compartment_conductance)\n",
    "\n",
    "        membrane_traces = self.record_membrane()\n",
    "        amplitudes = self.extract_psp_amplitudes(membrane_traces)\n",
    "        popt, pcov = self.fit_length_constant(amplitudes)\n",
    "        return popt, pcov, amplitudes\n",
    "\n",
    "    def evaluate(\n",
    "            self, individual: Sequence, target: float) -> float:\n",
    "        '''\n",
    "        Evaluation function used for the genetic algorithm.\n",
    "\n",
    "        Executes the experiment and fits an exponential to the maximum\n",
    "        amplitude of the EPSP in each compartment.\n",
    "\n",
    "        :param individual: Individual representing the settings of the leak and\n",
    "            inter-compartment conductance.\n",
    "        :param target: Target length constant.\n",
    "        :returns: The absolute difference between the target and the\n",
    "            individual's length constant.\n",
    "        '''\n",
    "        popt = self.run_and_eval(\n",
    "            leak_conductance=individual[0],\n",
    "            inter_compartment_conductance=individual[1])[0]\n",
    "        return (abs(popt[0] - target),)\n",
    "\n",
    "    @staticmethod\n",
    "    def fitfunc(location: Union[float, np.ndarray], length_const: float,\n",
    "                offset: float, scale: float) -> Union[float, np.ndarray]:\n",
    "        '''\n",
    "        Exponential function with offset.\n",
    "\n",
    "        :param location: Numerator inside the exponential.\n",
    "        :param length_const: Denominator inside the exponential.\n",
    "        :param offset: Y-offset of the exponential.\n",
    "        :param scale: Amplitude at Y-intercept.\n",
    "        :returns: Function evaluation provided the parameters.\n",
    "        '''\n",
    "        return scale * np.exp(- location / length_const) + offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9d620",
   "metadata": {},
   "source": [
    "### Overview of the experiment\n",
    "\n",
    "We run the experiment and visualize the attenuation of the EPSP along the chain.\n",
    "All plotting functions used in this tutorial are defined in this [helper file](_static/tutorial/ga_mc_helpers.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c3049",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import _static.tutorial.ga_mc_helpers as helpers\n",
    "\n",
    "\n",
    "pynn.setup(initial_config=calib)\n",
    "compartment_chain = CompartmentChain(length=5)\n",
    "compartment_chain.set_conductances(\n",
    "    leak_conductance=200,\n",
    "    inter_compartment_conductance=1000)\n",
    "membrane_traces = compartment_chain.record_membrane()\n",
    "helpers.plot_membrane_traces(membrane_traces, compartment_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2e6a66",
   "metadata": {},
   "source": [
    "Clearly, the attenuation of the EPSP with increasing distance from the EPSP initiation zone can be seen.\n",
    "The red dashed lines indicate the maximal amplitude $ U_\\mathrm{max} $ of the EPSP in the respective compartment.\n",
    "Please note that the baseline was subtracted in the second row of the figure since each neuron circuit has an individual recording offset.\n",
    "\n",
    "Next, we want to observe how the attenuation is affected by the two following parameters:\n",
    "\n",
    "- the leak conductance $ g_\\mathrm{leak} $  \n",
    "- the inter-compartment conductance $ g_\\mathrm{ic} $.  \n",
    "\n",
    "\n",
    "By varying those two parameters, we can see how the maximal EPSP amplitudes change.\n",
    "Furthermore, we fit an exponential function $ U_\\mathrm{max}(x)=\\exp(-x/\\lambda_\\mathrm{emp})+c $ to the decay of the EPSP amplitudes normed to the amplitude of the first compartment.\n",
    "The function parameter $ \\lambda_\\mathrm{emp} $ is the empirically determined length constant and approximately describes at which distance a signal decays to $ 1/e $ of its original amplitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fb205",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "old_data = []\n",
    "\n",
    "Slider = partial(widget.IntSlider, continuous_update=False)\n",
    "BoundedInt = partial(widget.BoundedIntText, continuous_update=False)\n",
    "\n",
    "@widget.interact(\n",
    "    g_leak=Slider(min=0, max=1022, step=10, value=500,\n",
    "                  description=r'$g_{\\mathrm{leak}}$'),\n",
    "    g_ic=Slider(min=0, max=1022, step=10, value=500,\n",
    "                description=r'$g_{\\mathrm{ic}}$'))\n",
    "def run_experiment(g_leak, g_ic):\n",
    "    popt, pcov, amplitudes = compartment_chain.run_and_eval(g_leak, g_ic)\n",
    "    helpers.visualize_experiment(\n",
    "        popt, pcov, amplitudes, compartment_chain, old_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67a368",
   "metadata": {},
   "source": [
    "In the following cell, you can compare the attenuation behavior of different parameterizations:\n",
    "1. Set “Old runs” to the number of configurations you want to compare.\n",
    "1. Use the sliders from the previous cell to set $ g_\\mathrm{leak} $ and $ g_\\mathrm{ic} $ to a configuration you want to investigate.\n",
    "1. Repeat from 2. for the next configuration you want to compare.\n",
    "1. Press “Display old runs” to display the “Old runs” last configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2d88ae",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "w = widget.interact_manual.options(manual_name=\"Display old runs\")\n",
    "\n",
    "w(helpers.display_old_runs, archive=widget.fixed(old_data),\n",
    "  n_last_runs=BoundedInt(min=1, max=10, step=1, value=1,\n",
    "                         description='Old runs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc91d9",
   "metadata": {},
   "source": [
    "In order to get a better understanding of how the conductances influence the length constant $ \\lambda_\\mathrm{emp} $, we sweep both parameters in a grid search.\n",
    "Note that depending on the `GRID_LENGTH` this might take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559a958b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "GRID_LENGTH = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb68451f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "lambdas = np.empty((GRID_LENGTH, GRID_LENGTH))\n",
    "\n",
    "conductances = np.linspace(0, 1000, GRID_LENGTH, dtype=int)\n",
    "\n",
    "for idx, [g_leak, g_ic] in enumerate(product(conductances, conductances)):\n",
    "    popt = compartment_chain.run_and_eval(\n",
    "        leak_conductance=g_leak, inter_compartment_conductance=g_ic)[0]\n",
    "    lambdas[idx % GRID_LENGTH, idx // GRID_LENGTH] = popt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e858139",
   "metadata": {},
   "source": [
    "Finally, we visualize the dependency of $ \\lambda_\\mathrm{emp} $ on $ g_\\mathrm{leak} $ and $ g_\\mathrm{ic} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a81f5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, figsize=(4, 4 * 1.1), tight_layout=True,\n",
    "                         gridspec_kw={'height_ratios': [1, 0.05]})\n",
    "helpers.plot_grid_search(fig, axes, lambdas, conductances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcb331",
   "metadata": {},
   "source": [
    "From the visualization of the grid search we can observe that a higher $ g_\\mathrm{ic} $ will result in a larger $ \\lambda_\\mathrm{emp} $.\n",
    "Furthermore, decreasing $ g_\\mathrm{leak} $ can also result in larger $ \\lambda_\\mathrm{emp} $, as the charge leaks more slowly from the membrane and therefore the EPSP can travel further down the chain.\n",
    "\n",
    "Through the grid search, we already obtained an estimate of how to choose our parameters $ g_\\mathrm{leak} $ and $ g_\\mathrm{ic} $ to obtain a certain $ \\lambda_\\mathrm{emp} $.\n",
    "However, if we want to find a precise setting, this brute force approach will become slow as a higher grid resolution will be necessary.\n",
    "Further, when adding more dimensions, the algorithm scales with $ N^d $, where $ N $ is the number of grid steps and $ d $ the number of dimensions.\n",
    "So when searching only one operating point, we can save a lot of computation time by not measuring all combinations but applying a genetic algorithm.\n",
    "Note that in contrast to the usual algorithms we use for calibration, like a binary search, this does not require assumptions about the hardware.\n",
    "\n",
    "We will now introduce genetic algorithms and use one to optimize $ g_\\mathrm{leak} $ and $ g_\\mathrm{ic} $ such that they result in a desired $ \\lambda_\\mathrm{emp} $.\n",
    "Note that this is only an illustration, as an operating point may usually be constrained by more target parameters, like a desired membrane time constant or given amplitudes per compartment.\n",
    "We will use the module deap [[For+12]](#for-12) to implement the genetic algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b1974",
   "metadata": {},
   "source": [
    "## Genetic Algorithm\n",
    "\n",
    "Genetic algorithms can be used for derivative-free optimizations and search tasks.\n",
    "The name is inspired by natural evolution as the algorithm borrows concepts from it [[Gol89]](#gol89).\n",
    "\n",
    "First, the algorithm creates a population of initial solutions.\n",
    "Every solution - referred to as an individual - is composed of genes that can be represented as numerical values.\n",
    "The numerical values are chosen randomly at the beginning of the algorithm.\n",
    "In an iterative procedure, individuals are mutated, recombined and selected, based on their fitness, i.e. how well they solve the problem.\n",
    "The iterations of this procedure are also called generations.\n",
    "This process stops if a satisfactory solution is found or until a predefined number of generations is reached.\n",
    "\n",
    "In the following, we will implement the genetic algorithm sketched in [figure 2](#figure-2) below.\n",
    "For our problem our individuals will consist out of two genes, which will be integer values describing the leak and inter-compartment conductance, bound to their respective limits.\n",
    "\n",
    "The population is initialized by randomly creating $ n= $`POPSIZE` individuals by drawing their genes from a uniform distributions over the search-boundaries.\n",
    "\n",
    "The evaluation-step is then done on BrainScaleS-2, where we configure the conductances according to an individual and run our above defined experiment.\n",
    "The fitness of that individual is then calculated by taking the absolute difference between the measured length constant $ \\lambda_\\mathrm{emp} $ and a predefined target length constant $ \\hat{\\lambda}_\\mathrm{emp} $.\n",
    "Next, individuals of the population are selected based on their fitness.\n",
    "Here we use tournament selection, which randomly picks `TOURNSIZE` individuals and selects the fittest of those.\n",
    "All individuals <sup>[1](#id6)</sup> of the tournament are then put back to the original population and the next tournament is started.\n",
    "Overall `POPSIZE` tournaments are run such that `POPSIZE` individuals are selected.\n",
    "\n",
    "Subsequently, the selected individuals are mutated and recombined.\n",
    "For recombination each individual is picked with probability `CXPB` and then from pairs of those picked individuals offspring is generated by mixing their genes (for details see [table 1](#table-1)).\n",
    "This functionality is provided by the `deap` method `tools.cxOnePoint`.\n",
    "An individual is mutated using `deap`’s `tools.mutUniformInt` method.\n",
    "This will happen with the probability `MUTPB` where each gene is randomly altered with probability `INDPB` (see [table 2](#table-2)).\n",
    "\n",
    "Finally, after those steps we end up with the next generation.\n",
    "Then the whole process - starting from the evaluation-step - repeats until the `NGEN`-th generation is reached.\n",
    "Ultimately, the fittest individual approximates a solution to our problem.\n",
    "\n",
    "<a id='id6'></a>\n",
    "**[1]** Including the just picked individuals.\n",
    "Note: This way the same individual can be picked multiple times for generating the next generation.\n",
    "Therefore `TOURNSIZE` should not be chosen too large to maintain exploration of the solution space.\n",
    "\n",
    "\n",
    "<a id='figure-2'></a>\n",
    "<img src=\"_static/tutorial/ga_mc_flowchart.png\" style=\"width:50%;\">\n",
    "\n",
    "Figure 2: Flowchart of a genetic algorithm.  \n",
    "\n",
    "<a id='table-1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecbcee",
   "metadata": {},
   "source": [
    "### Table 1: Recombination of two parents creating two offspring individuals.\n",
    "|Individual|Gene $ g_\\mathrm{l} $|Gene $ g_\\mathrm{ic} $|\n",
    "|:-------------------------------:|:-------------------------------:|:-------------------------------:|\n",
    "|Parent 1|64|852|\n",
    "|Parent 2|263|37|\n",
    "|Offspring 1|64|37|\n",
    "|Offspring 2|263|852|\n",
    "\n",
    "<a id='table-2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523918fe",
   "metadata": {},
   "source": [
    "### Table 2: Mutation of an individual.\n",
    "|Individual|Gene $ g_\\mathrm{l} $|Gene $ g_\\mathrm{ic} $|\n",
    "|:-------------------------------:|:-------------------------------:|:-------------------------------:|\n",
    "|Parent|64|852|\n",
    "|Offspring|64|663|\n",
    "<br/>\n",
    "\n",
    "Most of functionality we need is already provided by `deap` and we only have to pick the desired functions and hyper-parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b875b0",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# parameter limits g_leak and g_ic\n",
    "limits = np.array([(0, 1022), (0, 1022)]).T\n",
    "\n",
    "# number of individuals which will be picked for tournament selection\n",
    "TOURNSIZE = 2\n",
    "MUTPB = 0.2  # probability that individual is mutated\n",
    "# probability that a gene is mutated if individual is picked for mutation\n",
    "INDPB = 0.5\n",
    "CXPB = 0.3  # probability that this individual will be picked for crossover\n",
    "NGEN = 10  # number of generations until algorithm stops\n",
    "POPSIZE = 25  # number of individuals within each generation\n",
    "\n",
    "# container for various tools\n",
    "toolbox = deap.base.Toolbox()\n",
    "\n",
    "# define individual if not yet done\n",
    "if not hasattr(deap.creator, \"FitnessMin\"):\n",
    "    deap.creator.create(\"FitnessMin\", deap.base.Fitness, weights=(-1.0,))\n",
    "    deap.creator.create(\"Individual\", list, fitness=deap.creator.FitnessMin)\n",
    "\n",
    "\n",
    "def create_individual(lower_limit: np.ndarray,\n",
    "                      upper_limit: np.ndarray) -> Sequence:\n",
    "    '''\n",
    "    Creates an array of random integers of size 2 bounded to the provided\n",
    "    limits.\n",
    "\n",
    "    Values are drawn from a uniform distribution within\n",
    "    [lower_limit, upper_limit] for the respective gene.\n",
    "\n",
    "    :param lower_limit: Lower limits.\n",
    "    :param upper_limit: Upper limits.\n",
    "    :returns: Individual.\n",
    "    '''\n",
    "    ind = np.random.randint(lower_limit, upper_limit + 1)\n",
    "    return deap.creator.Individual(ind.tolist())\n",
    "\n",
    "\n",
    "toolbox.register(\"individual\", create_individual, limits[0], limits[1])\n",
    "toolbox.register(\"population\", deap.tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# define evolutionary operators\n",
    "toolbox.register(\"select\", deap.tools.selTournament, tournsize=TOURNSIZE)\n",
    "toolbox.register(\"mate\", deap.tools.cxOnePoint)\n",
    "toolbox.register(\"mutate\", deap.tools.mutUniformInt, low=list(limits[0]),\n",
    "                 up=list(limits[1]), indpb=INDPB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d62de4",
   "metadata": {},
   "source": [
    "We just defined the hyper-parameters of the genetic algorithm and how our individuals are generated and altered by the evolutionary operators.\n",
    "\n",
    "Now, we only need to define the target length constant and the evaluation function.\n",
    "The execution of experiments will suffer from trial-to-trial variations, which originate from the analog nature of the hardware.\n",
    "Therefore, the measured length constants might vary from run to run even though the configuration is the same.\n",
    "In order to later have the chance to interpret the results with respect to those trial-to-trial variations we define our target to be the averaged observed length constant found in 10 initial experiment runs using a fixed parameterization for $ g_\\mathrm{l} $ and $ g_\\mathrm{ic} $.\n",
    "From those 10 measurements we can calculate the standard deviation of the measured length constants, which can function as a rough estimation of the expected trial-to-trial variation during the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4309d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# fixed conductance parameters to generate target\n",
    "g_leak = 500\n",
    "g_ic = 500\n",
    "\n",
    "targets = []\n",
    "for _ in range(10):\n",
    "    popt = compartment_chain.run_and_eval(g_leak, g_ic)[0]\n",
    "    targets.append(popt[0])\n",
    "\n",
    "print(f\"Average target value: {np.mean(targets):.3f} +- \"\n",
    "      f\"{np.std(targets):.3f} compartments\")\n",
    "\n",
    "# evaluation function\n",
    "toolbox.register(\"evaluate\", compartment_chain.evaluate,\n",
    "                 target=np.mean(targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbaadc3",
   "metadata": {},
   "source": [
    "Note that we are interested in the individuals which reproduce our desired target length constant $ \\hat{\\lambda} $ as precise as possible.\n",
    "Therefore, our evaluation function calculates the deviation from an individual’s length constant $ \\lambda_{\\mathrm{emp}} $ to our desired target length constant $ \\hat{\\lambda} $:\n",
    "\n",
    "$$\n",
    "f = | \\lambda_{\\mathrm{emp}} - \\hat{\\lambda} | .\n",
    "$$\n",
    "\n",
    "This value is called fitness and for our task we want to minimize it.\n",
    "Here, this is achieved by choosing a negative weight in deap’s fitness function.\n",
    "During selection, this ensures, that individuals with a smaller fitness value are favored over those with a larger one.\n",
    "\n",
    "In the following, we define more visualization functions that will show how the population evolves in time and consequently run the genetic algorithm with the hyper-parameters defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9a498",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(8, 4 * 1.1), tight_layout=True,\n",
    "                         gridspec_kw={'height_ratios': [1, 0.05]})\n",
    "helpers.plot_fitness_population(axes[0, 1], POPSIZE, np.std(targets))\n",
    "helpers.plot_grid_search(fig, axes[:, 0], lambdas, conductances)\n",
    "# create empty scatter plot to later visualize the distribution of the\n",
    "# population over the grid plot\n",
    "scat = axes[0, 0].scatter([], [], c='C1', edgecolor='black', marker='X',\n",
    "                          s=200, alpha=0.4)\n",
    "# hide plot in bottom right\n",
    "axes[1, 1].axis('off')\n",
    "\n",
    "plt.close()\n",
    "output = widget.Output()\n",
    "display(output)\n",
    "\n",
    "\n",
    "def mean_fitness(population: Sequence) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the mean fitness of a population.\n",
    "\n",
    "    :param population: Population containing individuals.\n",
    "    :returns: Mean fitness of population.\n",
    "    \"\"\"\n",
    "    return np.mean([ind.fitness.values[0] for ind in population])\n",
    "\n",
    "\n",
    "def min_fitness(population: Sequence) -> float:\n",
    "    \"\"\"\n",
    "    Find minimum fitness of a population.\n",
    "\n",
    "    :param population: Population containing individuals.\n",
    "    :returns: Minimal fitness within a population.\n",
    "    \"\"\"\n",
    "    return np.min([ind.fitness.values[0] for ind in population])\n",
    "\n",
    "\n",
    "stats = deap.tools.Statistics(lambda ind: ind)\n",
    "stats.register(\"mean fitness\", mean_fitness)\n",
    "stats.register(\"min fitness\", min_fitness)\n",
    "stats.register(\"\", helpers.visualization, fig=fig, scat=scat,\n",
    "               output=output)\n",
    "pop, log = deap.algorithms.eaSimple(\n",
    "    toolbox.population(POPSIZE), toolbox, cxpb=CXPB, mutpb=MUTPB, ngen=NGEN,\n",
    "    stats=stats, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc78f32",
   "metadata": {},
   "source": [
    "In the right plot above, the gray lines represent the single individuals, the black line denotes the average performance of a generation and the blue line indicates the performance of the best individual within each generation.\n",
    "The horizontal black dashed line indicates the expected trial-to-trial variations of the experiment results with the parameterization from which we created our target length constant.\n",
    "We can see, that with increasing generations the average deviation from our target length constant is decreasing.\n",
    "Furthermore, we can see, that the best individuals are fluctuating and the deviation from the target value increases from time to time.\n",
    "This can have two reasons.\n",
    "First, mutation and recombination can alter the best performing individual such that its performance worsens, and second, since we work on an analog system, there are trial-to-trial variations.\n",
    "Consequently not every hardware run will yield the same result.\n",
    "However, both of this problems can be limited.\n",
    "\n",
    "By employing a so called elitism-mechanism [[De75]](#de75) to our genetic algorithm, one can ensure that the best performing individual of a generation is guaranteed to be unaltered passed on to the next generation.\n",
    "Therefore, the best fitness is preserved over the generations.\n",
    "\n",
    "Trial-to-trial variations of the hardware can be reduced by repeating the experiment and averaging the resulting EPSPs.\n",
    "\n",
    "Nevertheless, the above method should still provide us a sufficient chip parameterisation which results in our desired target length constant $ \\hat{\\lambda}_\\mathrm{emp} $.\n",
    "Finally, we execute the experiment 10 times with the configuration provided by the best individual of the last generation of the genetic algorithm.\n",
    "From the 10 runs we can get an estimate of the trial-to-trial variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c1e24b",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "best_ind_index = np.argmin([ind.fitness.values[0] for ind in pop])\n",
    "print(f\"Found parameters:\\nleak conductance:\\t\\t{pop[best_ind_index][0]}\\n\"\n",
    "      + f\"inter-compartment conductance:\\t{pop[best_ind_index][1]}\")\n",
    "lambdas_repeated = []\n",
    "for _ in range(10):\n",
    "    popt = compartment_chain.run_and_eval(*pop[best_ind_index])[0]\n",
    "    lambdas_repeated.append(popt[0])\n",
    "print(f\"Average measured length constant: {np.mean(lambdas_repeated):.3f} +- \"\n",
    "      + f\"{np.std(lambdas_repeated):.3f}\")\n",
    "print(f\"Target length constant: {np.mean(targets):.3f}\"\n",
    "      + f\" +- {np.std(targets):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9bd7e0",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id='vb99'></a>\n",
    "\\[VB99\\] Michael C Vanier and James M Bower. A comparative survey\n",
    "of automated parameter-search methods for compartmental\n",
    "neural models. J Comput Neurosci, 7(2):149–171, 1999.\n",
    "doi: 10.1023/a:1008972005316.\n",
    "\n",
    "<a id='bll01'></a>\n",
    "\\[BLL01\\] Thomas Berger, Matthew E. Larkum, and Hans-R. Lüscher.\n",
    "High I(h) channel density in the distal apical dendrite of\n",
    "layer V pyramidal cells increases bidirectional attenuation\n",
    "of EPSPs. J. Neurophysiol., 85(2):855–868, 2001. doi:\n",
    "10.1152/jn.2001.85.2.855.\n",
    "\n",
    "<a id='for-12'></a>\n",
    "\\[For+12\\] Félix-Antoine Fortin, François-Michel De Rainville, Marc-\n",
    "André Gardner, Marc Parizeau, and Christian Gagné. DEAP:\n",
    "Evolutionary algorithms made easy. Journal of Machine\n",
    "Learning Research, 13:2171–2175, July 2012.\n",
    "\n",
    "<a id='gol89'></a>\n",
    "\\[Gol89\\] David E. Goldberg. Genetic Algorithms in Search, Optimization\n",
    "and Machine Learning. Addison Wesley Longman Inc.,\n",
    "1989. ISBN 0-201-15767-5.\n",
    "\n",
    "<a id='de75'></a>\n",
    "\\[De75\\] Kenneth Alan De Jong. An analysis of the behavior of a class\n",
    "of genetic adaptive systems. PhD thesis, 1975."
   ]
  }
 ],
 "metadata": {
  "date": 1728385271.6404061,
  "filename": "ts_04-mc_genetic_algorithms.rst",
  "kernelspec": {
   "display_name": "EBRAINS-experimental",
   "language": "python",
   "name": "ebrains-experimental"
  },
  "title": "How to use Genetic Algorithms to automatically parameterize BrainScaleS-2"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
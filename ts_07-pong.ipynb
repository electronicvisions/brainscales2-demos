{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0581553",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import enum\n",
    "from typing import Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import textwrap\n",
    "import pickle\n",
    "import struct\n",
    "import time\n",
    "import ipywidgets as widgets\n",
    "import IPython.display\n",
    "\n",
    "import numpy as np\n",
    "import quantities as pq\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dlens_vx_v3 import halco, hal, sta, lola\n",
    "\n",
    "import pynn_brainscales.brainscales2 as pynn\n",
    "\n",
    "from _static.common.helpers import save_nightly_calibration\n",
    "from _static.tutorial.pong_demo_helpers import Parameters, ExperimentData, PongGame\n",
    "\n",
    "from contextlib import suppress\n",
    "with suppress(IOError):\n",
    "    plt.style.use(\"_static/matplotlibrc\")\n",
    "\n",
    "# setup shared connection to hardware\n",
    "from _static.common.helpers import setup_hardware_client\n",
    "setup_hardware_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b11a7d",
   "metadata": {},
   "source": [
    "# Pong\n",
    "\n",
    "This notebook aims at learning the Pong game. A ball is played between\n",
    "two players, mimicking table tennis. Each player controls a paddle that\n",
    "reflects the ball, as shown below. We will train a neural network that\n",
    "controls the right player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b584b1",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# display a perfectly played pong game - without any neural network so far.\n",
    "pong_game = PongGame(demo=True)\n",
    "pong_game.run()  # runs a perfect game\n",
    "pong_game.animate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7eac3",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "\n",
    "BrainScaleS-2 will learn to control one of the paddles to track the\n",
    "pong ball at all times, thus learning to play the game.\n",
    "The chip is supplied with the vertical\n",
    "position of the ball - encoded by a uniform spiketrain to an input\n",
    "neuron (left column “input spikes” in figure below). A matrix of\n",
    "excitatory synapses densely connects the input to output neurons (shown\n",
    "as green dots in figure below, the intensity represents the weight of\n",
    "the synapse). The paddle moves to the position encoded by the\n",
    "most-active output neuron (row “output spikes” below the neurons in\n",
    "figure below). The network does not have a concept of time, it will only\n",
    "return a paddle position for an input ball position. Thus, we will query\n",
    "thet network regularly to have the paddle track the ball. Both the ball\n",
    "and the paddle have a certain size, i.e. the input spikes are\n",
    "distributed to more than one synapse row and the most-active neuron can\n",
    "be a bit besides the center of the ball.\n",
    "\n",
    "The ball and paddle positions are mapped to the synapse matrix linearly,\n",
    "so a diagonal matrix will be able to play the game perfectly - that is,\n",
    "as long as the paddle moves quickly with respect to the ball, which we\n",
    "allow here. In the figure below, we indicate this perfect paddle\n",
    "position by the red arrow through the synapse matrix. In this example\n",
    "however, the most-active neuron is outside the paddle size, so the\n",
    "paddle would move further to the right and would miss the ball.\n",
    "\n",
    "<img src=\"_static/tutorial/pong_encoding.png\" alt=\"Encoding and reward for pong game\" style=\"width:1000px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a7df8",
   "metadata": {},
   "source": [
    "## Learning rule\n",
    "\n",
    "We use reward-modulated spike timing dependent plasticity (R-STDP)\n",
    "[[Michael and Fairhall,\n",
    "2007]](https://journals.physiology.org/doi/full/10.1152/jn.00364.2007)\n",
    "to learn the game, as described in the following. This implementation is\n",
    "close to [Timo Wunderlich et\n",
    "al. (2019)](https://www.frontiersin.org/articles/10.3389/fnins.2019.00260/full),\n",
    "but here we do not go as far as implementing the whole pong game on the\n",
    "chip’s digital microprocessor, we will only execute the learning\n",
    "algorithm locally on chip. Furthermore, the network now runs on a much\n",
    "larger synapse matrix, which has required a few changes.\n",
    "\n",
    "Training is controlled by maximizing a reward. The reward is a metric\n",
    "for the performance of the player in a given scenario, i.e. the spike\n",
    "counts per neuron for a certain ball position. Spikes of neurons closer\n",
    "to the center of the paddle are rewarded more strongly, spikes of neurons\n",
    "that still result in the ball hitting the paddle increase the\n",
    "reward only slightly, and spikes outside the width of the paddle\n",
    "decrease the reward. In the\n",
    "figure above, we plot the reward multiplicator, which yields positive\n",
    "rewards only in the region where the paddle should have moved to. And\n",
    "below that we show the contributions of the individual neurons to the\n",
    "total reward, which are the product of the spike count and the reward\n",
    "multiplier.\n",
    "\n",
    "For each network run, we calculate the instantaneous reward and compare\n",
    "it to an exponentially weighted expected reward from the previous runs.\n",
    "The strength of the weight update is scaled with this reward delta,\n",
    "which can be positive or negative. If the network performs better than\n",
    "before, the weights will be updated according to the measured\n",
    "correlation between pre- and postsynaptic spikes (STDP). In case the\n",
    "network performs worse than before, the weight update is inverted. The\n",
    "weight update $ \\Delta w_{ij} $ is given by the following learning\n",
    "rule, where $ \\beta $ is the learning rate, $ R $ the\n",
    "instantaneous reward, $ \\bar{R} $ the expected reward from previous\n",
    "runs, the index $ k $ denotes the ball position, and\n",
    "$ \\text{corr}_{ij} $ is the causal correlation observed by each\n",
    "synapse:\n",
    "\n",
    "$$\n",
    "\\Delta w_{ij} = \\beta \\cdot (R_k - \\bar{R_k}) \\cdot \\text{corr}_{ij}\n",
    "$$\n",
    "\n",
    "During training, we present all possible ball positions once in what we\n",
    "call an epoch. For all individual ball positions, we apply random noise\n",
    "to the neurons, implemented as a synapse row with randomly drawn\n",
    "weights. This allows for exploring all options within the synapse\n",
    "matrix. The reward and correlation are calculated based on all\n",
    "postsynaptic spikes, including those injected by noise - so the weights\n",
    "will increase in case the random noise pattern matches the desired\n",
    "outcome.\n",
    "\n",
    "Noise is required for this training algorithm to work, as it allows\n",
    "exploration in the beginning of the training. During the training, we\n",
    "linearly decrease the injected noise amplitude. This is implemented as\n",
    "decreasing the standard deviation of the noise weights, which are drawn\n",
    "from approximately a normal distribution. In order to have a rather\n",
    "sparse noise distribution, its mean is shifted to below zero, and all\n",
    "weights below zero are clipped. During initial training, the output\n",
    "spikes are mainly generated by noise, while finally, they are mainly\n",
    "generated by trained weights.\n",
    "\n",
    "Lastly, at the end of an epoch, we employ a homeostasis rule to control\n",
    "the total number of spikes. In case a neuron spikes too often within an\n",
    "epoch, all weights of its column of input synapses will be decreased (or\n",
    "increased if it spikes not often enough). In the beginning of the\n",
    "training, we exceed the homeostasis target spike count already as a\n",
    "result of noise input. This means that only fast-growing weights will be\n",
    "able to persist initially.\n",
    "\n",
    "To summarize, within one epoch, we present all possible input ball\n",
    "positions once. For each ball position, a new set of noise weights is\n",
    "drawn, the network is run, the weights are updated based on the\n",
    "reward-modulated STDP rule, and the expected reward is updated with the\n",
    "newly observed reward. Finally, the homeostasis rule is applied based on\n",
    "the total spike counts within the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b1873",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "The following code implements this learning rule in PyNN. We send the\n",
    "spike inputs for an epoch from the host, but handle the learning rule on\n",
    "the plasticity-processing unit (PPU), locally on the chip. The PPU will\n",
    "read the spike counters, calculate a reward, compare it to the\n",
    "previously obtained rewards to get a weight update rate, and update the\n",
    "weights based on measured causal correlation. Before processing the next\n",
    "input sample, the PPU draws new random weights for the noise row, and\n",
    "resets spike counters and correlation data.\n",
    "\n",
    "Since the PPU handles all training, we train multiple epochs\n",
    "in one PyNN call. The number of epochs trained in one hardware run is\n",
    "only limited by the maximum runtime of PyNN. There is no reason to keep\n",
    "the host computer in the loop, we only read back the updated weights\n",
    "from the chip after each PyNN run.\n",
    "\n",
    "In the following cell, we define parameters for the experiment. Feel\n",
    "free to modify them and explore! The default parameters should learn the\n",
    "game rather quickly, within some 300 epochs. (After changing parameters,\n",
    "you need to re-execute all cells in the rest of the notebook, for the\n",
    "changes to be effective.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba31260",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Create an instance of the dataclass `Parameters`, which is used\n",
    "# throughout this notebook. The values are set in this cell.\n",
    "parameters = Parameters()\n",
    "\n",
    "# Number of total epochs, in which noise is reduced from start to end.\n",
    "# The notebook will not execute all those by default, we will train\n",
    "# only a few hundred epochs at the end.\n",
    "parameters.noise_range_epochs = 500\n",
    "\n",
    "# Number of input rows.\n",
    "parameters.n_inputs = 100\n",
    "\n",
    "# Number of output neurons.\n",
    "# Fundamentally, the pong task works with an equal number of inputs\n",
    "# and outputs. In case you add more outputs, the weights of\n",
    "# synapses in the additional columns will remain low.\n",
    "parameters.n_outputs = 100\n",
    "\n",
    "# Select distribution of input events across multiple rows.\n",
    "# In order to not depend on all correlation sensors etc. working\n",
    "# perfectly, we distribute the input events across multiple synapse\n",
    "# rows. This list contains the relative event rates for further\n",
    "# rows. Example: A configuration `input_distribution = [1, 0.7, 0.3]`\n",
    "# will send the full rate to the middle row, 0.7 times the full rate\n",
    "# to the rows one above and below, and 0.3 times the full rate to the\n",
    "# rows two above and below.\n",
    "parameters.input_distribution = [1, 0.8, 0.5, 0.1]\n",
    "\n",
    "# Number of input events sent to middle (\"target\") input row.\n",
    "parameters.n_events = 140\n",
    "\n",
    "# Inter-spike interval for input events in middle input row.\n",
    "parameters.wait_between_events = 4.20 * pq.us\n",
    "\n",
    "# Inter-spike interval for noise events. The noise is applied for\n",
    "# the same time-duration as the inputs.\n",
    "parameters.wait_between_noise = 3.5 * pq.us\n",
    "\n",
    "# Standard deviation of noise weight distribution. The noise weights\n",
    "# are drawn from an approximated normal distribution. The standard\n",
    "# deviation is reduced linearly during training, from the configured\n",
    "# start to end values.\n",
    "parameters.noise_range_start = 15\n",
    "parameters.noise_range_end = 4\n",
    "\n",
    "# Reward for each neuron depending on the distance from the target\n",
    "# neuron. The number of spikes of each neuron is multiplied with the\n",
    "# factor given here, and the sum of these products is the reward for\n",
    "# an experiment run.\n",
    "parameters.rewards = {  # dict key: distance from target; value: reward factor\n",
    "    0: 4,  # at target neuron\n",
    "    1: 3,  # 1 left or right of target\n",
    "    2: 2,  # 2 left or right of target\n",
    "    3: 2,  # ...\n",
    "    4: 1,\n",
    "    5: 1,\n",
    "    6: 0,\n",
    "    \"elsewhere\": -1\n",
    "    # Reward \"elsewhere\" must be below 0. All rewards below zero are\n",
    "    # assumed to have missed the paddle, zero and greater rewards are\n",
    "    # assumed to have hit the paddle.\n",
    "}\n",
    "\n",
    "# Learning rate.\n",
    "parameters.learning_rate = 0.01\n",
    "\n",
    "# Target spikes per column in an epoch for homeostasis.\n",
    "parameters.homeostasis_target = 3 * parameters.n_inputs\n",
    "\n",
    "# Update rate for homeostasis, in weight LSB.\n",
    "parameters.homeostasis_rate = 1. / parameters.homeostasis_target\n",
    "\n",
    "# Reward decay: Update rate of average reward in each epoch. The reward\n",
    "# is updated with the new, instantaneous reward in each epoch. A high\n",
    "# decay means that the average reward closely follows the state in each\n",
    "# epoch, a low decay means that the average reward changes only slowly\n",
    "# with the new results in each epoch.\n",
    "parameters.reward_decay = 0.5\n",
    "\n",
    "# Number of epochs that are executed initially without learning, in\n",
    "# order to initialize the average reward.\n",
    "parameters.reward_initialization_phase = 10\n",
    "\n",
    "### Timing properties - expect broken results when reducing them below the required time!\n",
    "# Scheduled time for initialization, such as correlation resets\n",
    "parameters.init_duration = 1 * pq.ms\n",
    "\n",
    "# Scheduled time for handling plasticity kernel\n",
    "# You may need to increase this value when using a higher number of inputs.\n",
    "parameters.plasticity_duration = 2.5 * pq.ms\n",
    "\n",
    "# Number of epochs executed within one pynn.run() call.\n",
    "# Note: learning rate is only updated at compile-time, i.e.\n",
    "# will not be updated during the epochs within a PyNN run.\n",
    "parameters.epochs_per_run = 10\n",
    "\n",
    "# set variables that will be used later in this script\n",
    "epoch = 0\n",
    "rewards = np.ones(parameters.n_inputs)\n",
    "logical_weights = None\n",
    "data = ExperimentData(epochs_per_run=parameters.epochs_per_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85b4fa0",
   "metadata": {},
   "source": [
    "We now define two plasticity rules: `NoiseSynapseRule` handles\n",
    "initialization and draws a new random distribution of noise weights,\n",
    "while `PlasticityRule` handles the reward-modulated STDP learning\n",
    "rule.\n",
    "\n",
    "Both plasticity rules are Python classes that generate and return a\n",
    "`c++` code snippet that will be compiled and executed on the PPU. For\n",
    "readability, we print the returned code with `c++` syntax highlighting\n",
    "below the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed57a4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class NoiseSynapseRule(pynn.PlasticityRule):\n",
    "    \"\"\"\n",
    "    Draw a new set of noise weights after each input row, and do further\n",
    "    initialization tasks.\n",
    "    \"\"\"\n",
    "\n",
    "    def generate_kernel(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate plasticity rule kernel to be compiled into PPU program.\n",
    "\n",
    "        :return: PPU-code of plasticity-rule kernel as string.\n",
    "        \"\"\"\n",
    "        return textwrap.dedent(f\"\"\"\n",
    "        #include \"grenade/vx/ppu/synapse_array_view_handle.h\"\n",
    "        #include \"grenade/vx/ppu/neuron_view_handle.h\"\n",
    "        #include \"libnux/vx/correlation.h\"\n",
    "        #include \"libnux/vx/dls.h\"\n",
    "        #include \"libnux/vx/vector_row.h\"\n",
    "        #include \"libnux/vx/vector_if.h\"\n",
    "        #include \"libnux/vx/parallel_rng.h\"\n",
    "        #include \"libnux/vx/reset_neurons.h\"\n",
    "        #include \"stadls/vx/v3/ppu/write.h\"\n",
    "\n",
    "        using namespace grenade::vx::ppu;\n",
    "        using namespace libnux::vx;\n",
    "\n",
    "        // PPU currently executing this code (top/bottom).\n",
    "        extern volatile PPUOnDLS ppu;\n",
    "\n",
    "        /**\n",
    "         * Initialize the random number generator by selecting a seed\n",
    "         * and drawing a few random numbers initially.\n",
    "         */\n",
    "        class RNGInit\n",
    "        {{\n",
    "            public:\n",
    "            RNGInit()\n",
    "            {{\n",
    "                parallel_rng_seed(VectorRowMod8({np.random.randint(1, 256)}));\n",
    "                for (size_t i = 0; i < 234 + {epoch}; ++i)\n",
    "                    parallel_rng_rand<VectorRowMod8>();\n",
    "            }}\n",
    "        }};\n",
    "        RNGInit rng_init;\n",
    "\n",
    "        void PLASTICITY_RULE_KERNEL(\n",
    "            std::array<SynapseArrayViewHandle, 1>& synapses,\n",
    "            std::array<NeuronViewHandle, 0>& /* neurons */)\n",
    "        {{\n",
    "            // only continue if code is executed on the correct PPU\n",
    "            if (synapses[0].hemisphere != ppu) {{\n",
    "                return;\n",
    "            }}\n",
    "\n",
    "            // pick a new row of random weights:\n",
    "            // Use 12 random vectors with a uniform distribution and summarize\n",
    "            // them as approximation of a normal distribution. After bit-shifting,\n",
    "            // the sum of the vectors represents a distribution with roughly\n",
    "            // a mean of -4.5 and a standard deviation of 32.\n",
    "            VectorRowFracSat16 accumulator;\n",
    "            for (size_t i = 0; i < 12; ++i)\n",
    "            {{\n",
    "                accumulator += VectorRowFracSat16(\n",
    "                    parallel_rng_rand<VectorRowFracSat8>() >> 3);\n",
    "                // Draw more vectors to avoid summarizing correlated ones:\n",
    "                // Draw at least the number of used bits, since we only\n",
    "                // get one new random bit per draw\n",
    "                for (size_t j = 0; j < 13; ++j)\n",
    "                    parallel_rng_rand<VectorRowFracSat8>();\n",
    "            }}\n",
    "            VectorRowFracSat8 accumulator_8 = VectorRowFracSat8(accumulator - 6);\n",
    "            VectorRowFracSat8 random = VectorRowFracSat8(\n",
    "                accumulator_8 * ({parameters.get_noise_range(epoch)} * 4));\n",
    "\n",
    "            random = vector_if(\n",
    "                random, VectorIfCondition::lesser, VectorRowFracSat8(0), random);\n",
    "            random = vector_if(\n",
    "                random - 63, VectorIfCondition::greater, VectorRowFracSat8(63), random);\n",
    "            for (size_t row = 0; row < synapses[0].rows.size(); ++row) {{\n",
    "                synapses[0].set_weights(VectorRowMod8(random), row);\n",
    "            }}\n",
    "\n",
    "            // prepare for next correlation experiment:\n",
    "            reset_neurons();\n",
    "\n",
    "            // reset spike counters\n",
    "            for (size_t i = 0; i < {parameters.n_outputs}; ++i)\n",
    "            {{\n",
    "                auto coord = halco::hicann_dls::vx::v3::AtomicNeuronOnDLS(\n",
    "                    halco::hicann_dls::vx::v3::NeuronColumnOnDLS(i),\n",
    "                    halco::hicann_dls::vx::v3::NeuronRowOnDLS()\n",
    "                ).toSpikeCounterResetOnDLS();\n",
    "                stadls::vx::v3::ppu::write(\n",
    "                    coord, haldls::vx::v3::SpikeCounterReset());\n",
    "            }}\n",
    "\n",
    "            reset_all_correlations();\n",
    "        }}\n",
    "        \"\"\")\n",
    "\n",
    "# create a timer that controls when this plasticity rule is executed\n",
    "init_timer = pynn.Timer(\n",
    "    start=0,\n",
    "    period=parameters.row_duration.rescale(pq.ms).magnitude,\n",
    "    num_periods=parameters.n_inputs * parameters.epochs_per_run)\n",
    "\n",
    "# print returned PPU kernel code with c++ syntax highlighting\n",
    "class DemoRule(NoiseSynapseRule):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "ppu_code = DemoRule().generate_kernel()\n",
    "IPython.display.display_markdown(IPython.display.Markdown(f\"``` c++ \\n{ppu_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee02a23",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "class PlasticityRule(pynn.PlasticityRule):\n",
    "    \"\"\"\n",
    "    Update synapse weights according to STDP learning rule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, timer: pynn.Timer, same_id: int):\n",
    "        \"\"\"\n",
    "        Initialize plastic synapse with execution timing information,\n",
    "        hyperparameters and initial weight.\n",
    "        \"\"\"\n",
    "\n",
    "        observables = {\n",
    "            \"rewards\": pynn.PlasticityRule.ObservableArray(),\n",
    "            \"success\": pynn.PlasticityRule.ObservableArray()\n",
    "        }\n",
    "        observables[\"rewards\"].type = \\\n",
    "            pynn.PlasticityRule.ObservableArray.Type.uint8\n",
    "        observables[\"rewards\"].size = 4\n",
    "        observables[\"success\"].type = \\\n",
    "            pynn.PlasticityRule.ObservableArray.Type.uint8\n",
    "        observables[\"success\"].size = 1\n",
    "\n",
    "        super().__init__(\n",
    "            timer=timer, observables=observables, same_id=same_id)\n",
    "\n",
    "    def generate_kernel(self) -> str:\n",
    "        \"\"\"\n",
    "        Generate plasticity rule kernel to be compiled into PPU program.\n",
    "\n",
    "        :return: PPU-code of plasticity-rule kernel as string.\n",
    "        \"\"\"\n",
    "\n",
    "        ppucode = textwrap.dedent(f\"\"\"\n",
    "        #include <algorithm>\n",
    "        #include \"grenade/vx/ppu/synapse_array_view_handle.h\"\n",
    "        #include \"grenade/vx/ppu/neuron_view_handle.h\"\n",
    "        #include \"libnux/vx/correlation.h\"\n",
    "        #include \"libnux/vx/dls.h\"\n",
    "        #include \"libnux/vx/vector_row.h\"\n",
    "        #include \"libnux/vx/vector_if.h\"\n",
    "        #include \"libnux/vx/mailbox.h\"\n",
    "        #include \"libnux/vx/time.h\"\n",
    "        #include \"stadls/vx/v3/ppu/read.h\"\n",
    "\n",
    "        using namespace grenade::vx::ppu;\n",
    "        using namespace libnux::vx;\n",
    "\n",
    "        /**\n",
    "         * PPU currently executing this code (top/bottom).\n",
    "         */\n",
    "        extern volatile PPUOnDLS ppu;\n",
    "\n",
    "        /**\n",
    "         * Mean rewards, updated exponentially each epoch\n",
    "         */\n",
    "        float mean_rewards[{parameters.n_inputs}] = {{\n",
    "            {\", \".join(rewards.astype(str))}\n",
    "        }};\n",
    "\n",
    "        /**\n",
    "         * Baseline reads from correlation sensors, one per column.\n",
    "         */\n",
    "        VectorRowMod8 get_baselines()\n",
    "        {{\n",
    "            reset_all_correlations();\n",
    "\n",
    "            VectorRowMod16 accumulator(0);\n",
    "            for (size_t row = 0; row < 256; ++row)\n",
    "            {{\n",
    "                VectorRowMod8 result;\n",
    "                get_causal_correlation(&result.even.data, &result.odd.data, row);\n",
    "                accumulator += static_cast<VectorRowMod16>(result);\n",
    "            }}\n",
    "\n",
    "            return VectorRowMod8(accumulator >> 8);\n",
    "        }}\n",
    "        VectorRowMod8 correlation_baselines = get_baselines();\n",
    "\n",
    "        /**\n",
    "         * Accumulated spikes per neuron (per epoch).\n",
    "         */\n",
    "        uint16_t all_spikes[{parameters.n_outputs}] = {{\n",
    "            {\", \".join([\"0\" for _ in range(parameters.n_outputs)])} }};\n",
    "\n",
    "        /**\n",
    "         * Currently active input row.\n",
    "         */\n",
    "        size_t current_row = 0;\n",
    "\n",
    "        VectorRowFracSat8 check_boundaries(VectorRowFracSat8 vec)\n",
    "        {{\n",
    "            vec = vector_if(\n",
    "                vec, VectorIfCondition::greater,\n",
    "                vec, VectorRowFracSat8(0));\n",
    "            vec = vector_if(\n",
    "                vec - 63, VectorIfCondition::greater,\n",
    "                VectorRowFracSat8(63), vec);\n",
    "\n",
    "            return vec;\n",
    "        }}\n",
    "\n",
    "        void PLASTICITY_RULE_KERNEL(\n",
    "            std::array<SynapseArrayViewHandle, 1>& synapses,\n",
    "            std::array<NeuronViewHandle, 0>& /* neurons */,\n",
    "            Recording& recording)\n",
    "        {{\n",
    "            // only continue if code is executed on the correct PPU\n",
    "            if (synapses[0].hemisphere != ppu) {{\n",
    "                return;\n",
    "            }}\n",
    "\n",
    "            recording.time = 0;\n",
    "\n",
    "            // generate reward vector for current row\n",
    "            int reward_array[{parameters.n_outputs}];\n",
    "            for (size_t i = 0; i < {parameters.n_outputs}; ++i)\n",
    "            {{\"\"\")\n",
    "\n",
    "        # generate code for reward vector based on dict in parameters\n",
    "        first_branch = True\n",
    "        for key, value in parameters.rewards.items():\n",
    "            if key == \"elsewhere\":\n",
    "                continue\n",
    "            branching = \"else if\" if not first_branch else \"if\"\n",
    "            ppucode += textwrap.indent(textwrap.dedent(f\"\"\"\n",
    "                {branching} ((i == current_row - {key}) || (i == current_row + {key}))\n",
    "                    reward_array[i] = {value};\"\"\"), \"\\t\\t\")\n",
    "            first_branch = False\n",
    "\n",
    "        ppucode += textwrap.dedent(f\"\"\"\n",
    "                else\n",
    "                    reward_array[i] = {parameters.rewards[\"elsewhere\"]};\n",
    "            }}\n",
    "\n",
    "            // read out spike counters\n",
    "            size_t spike_counts[{parameters.n_outputs}];\n",
    "            for (size_t i = 0; i < {parameters.n_outputs}; ++i)\n",
    "            {{\n",
    "                auto coord = halco::hicann_dls::vx::v3::AtomicNeuronOnDLS(\n",
    "                    halco::hicann_dls::vx::v3::NeuronColumnOnDLS(i),\n",
    "                    halco::hicann_dls::vx::v3::NeuronRowOnDLS()\n",
    "                ).toSpikeCounterReadOnDLS();\n",
    "                haldls::vx::v3::SpikeCounterRead container =\n",
    "                    stadls::vx::v3::ppu::read<\n",
    "                    haldls::vx::v3::SpikeCounterRead>(coord);\n",
    "                spike_counts[i] = container.get_count();\n",
    "                if (current_row > 0)\n",
    "                    all_spikes[i] += spike_counts[i];\n",
    "            }}\n",
    "\n",
    "            // calculate reward and weight update rate\n",
    "            int accumulator = 0;\n",
    "            for (size_t i = 0; i < {parameters.n_outputs}; ++i)\n",
    "                accumulator += reward_array[i] * spike_counts[i];\n",
    "            float reward = accumulator / 100.;\n",
    "            float update_rate = (reward - mean_rewards[current_row])\n",
    "                * {parameters.get_learning_rate(epoch)};\n",
    "\n",
    "            // update weights\n",
    "            for (size_t row = 0; row < synapses[0].rows.size(); ++row) {{\n",
    "                VectorRowMod8 weights = synapses[0].get_weights(row);\n",
    "                VectorRowMod8 result;\n",
    "                get_causal_correlation(&result.even.data, &result.odd.data, synapses[0].rows[row]);\n",
    "\n",
    "                // shift result by 1 bit to stay in signed 8-bit int range\n",
    "                VectorRowFracSat8 result_fracsat =\n",
    "                    (result >> 1).convert_contiguous();\n",
    "                VectorRowFracSat8 baselines_fracsat =\n",
    "                    (correlation_baselines >> 1).convert_contiguous();\n",
    "                VectorRowFracSat8 correlation_fracsat =\n",
    "                    baselines_fracsat - result_fracsat;\n",
    "\n",
    "                // multiplication of fracsat type scales down by 128 to\n",
    "                // ensure we stay in value range, hence we multiply\n",
    "                // the update_rate by 128\n",
    "                VectorRowFracSat8 weight_update =\n",
    "                    correlation_fracsat * static_cast<int8_t>(update_rate * 128);\n",
    "\n",
    "                // truncate weight update, i.e. round symetrically to zero:\n",
    "                // for negative updates, we want to add 1.\n",
    "                weight_update = vector_if(\n",
    "                    weight_update, VectorIfCondition::lesser,\n",
    "                    weight_update + 1, weight_update);\n",
    "                VectorRowFracSat8 new_weights =\n",
    "                    static_cast<VectorRowFracSat8>(weights)\n",
    "                    + weight_update;\n",
    "\n",
    "                // clip weights to hardware range limits\n",
    "                new_weights = check_boundaries(new_weights);\n",
    "                weights = static_cast<VectorRowMod8>(new_weights);\n",
    "\n",
    "                synapses[0].set_weights(weights, row);\n",
    "            }}\n",
    "\n",
    "            // update mean rewards\n",
    "            mean_rewards[current_row] =\n",
    "                ({1 - parameters.get_reward_decay(epoch)} * mean_rewards[current_row])\n",
    "                + ({parameters.get_reward_decay(epoch)} * reward);\n",
    "\n",
    "            // record mean reward:\n",
    "            // The float value is casted to a char array to be passed to an\n",
    "            // observable, since we have no float observables in PyNN yet.\n",
    "            unsigned char array[4];\n",
    "            *reinterpret_cast<float*>(array) = mean_rewards[current_row];\n",
    "            for (size_t i = 0; i < 4; ++i)\n",
    "                recording.rewards[i] = array[i];\n",
    "\n",
    "            // record success\n",
    "            unsigned int paddle_position =\n",
    "                std::max_element(&spike_counts[0],\n",
    "                                 &spike_counts[{parameters.n_outputs}])\n",
    "                - &spike_counts[0];\n",
    "            if (reward_array[paddle_position] >= 0)\n",
    "                recording.success[0] = 1;\n",
    "            else\n",
    "                recording.success[0] = 0;\n",
    "\n",
    "            // apply homeostasis at end of epoch\n",
    "            if (current_row == {parameters.n_inputs - 1})\n",
    "            {{\n",
    "                VectorRowFracSat8 update(0);\n",
    "\n",
    "                for (size_t column = 0; column < {parameters.n_outputs}; ++column)\n",
    "                {{\n",
    "                    int16_t deviation =\n",
    "                        {parameters.homeostasis_target} - all_spikes[column];\n",
    "                    update[column] =\n",
    "                        deviation * {parameters.homeostasis_rate};\n",
    "                }}\n",
    "\n",
    "                for (size_t row = 0; row < synapses[0].rows.size(); ++row) {{\n",
    "                    VectorRowMod8 weights = synapses[0].get_weights(row);\n",
    "                    VectorRowFracSat8 new_weights =\n",
    "                        static_cast<VectorRowFracSat8>(weights) + update;\n",
    "\n",
    "                    new_weights = check_boundaries(new_weights);\n",
    "                    weights = static_cast<VectorRowMod8>(new_weights);\n",
    "\n",
    "                    synapses[0].set_weights(weights, row);\n",
    "                }}\n",
    "\n",
    "                // reset row counter and spike accumulators\n",
    "                current_row = 0;\n",
    "                for (size_t i = 0; i < {parameters.n_outputs}; ++i)\n",
    "                    all_spikes[i] = 0;\n",
    "            }}\n",
    "            else\n",
    "                current_row++;\n",
    "        }}\n",
    "        \"\"\")\n",
    "\n",
    "        return ppucode\n",
    "\n",
    "# create a timer that controls when this plasticity rule is executed\n",
    "plasticity_timer = pynn.Timer(\n",
    "    start=(parameters.input_duration + parameters.init_duration\n",
    "           ).rescale(pq.ms).magnitude,\n",
    "    period=parameters.row_duration.rescale(pq.ms).magnitude,\n",
    "    num_periods=parameters.n_inputs * parameters.epochs_per_run)\n",
    "\n",
    "# print returned PPU kernel code with c++ syntax highlighting\n",
    "class DemoRule(PlasticityRule):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "ppu_code = DemoRule().generate_kernel()\n",
    "IPython.display.display_markdown(IPython.display.Markdown(f\"``` c++ \\n{ppu_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4871dca",
   "metadata": {},
   "source": [
    "We will now create all necessary objects for PyNN to handle the\n",
    "training.\n",
    "\n",
    "More specifically, we…\n",
    "* load a calibration for neurons and correlation sensors\n",
    "* create populations and projections\n",
    "* create input spiketrains handling multiple desired epochs in one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae1669",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# download latest calibration\n",
    "save_nightly_calibration(\n",
    "    filename=\"correlation_calix-native.pkl\", source_folder=\"latest-weekly\")\n",
    "\n",
    "# load calibration\n",
    "with open(\"correlation_calix-native.pkl\", \"rb\") as calibfile:\n",
    "    calib_result = pickle.load(calibfile)\n",
    "\n",
    "# The correlation voltages are set on the board and therefore\n",
    "# are not contained in lola.Chip(), so we inject them as a builder\n",
    "injected_config = pynn.InjectedConfiguration()\n",
    "calib_builder = sta.PlaybackProgramBuilder()\n",
    "calib_result.apply(calib_builder)\n",
    "injected_config.pre_static_config = calib_builder\n",
    "\n",
    "calib_dumper = sta.PlaybackProgramBuilderDumper()\n",
    "calib_result.apply(calib_dumper)\n",
    "calib_dumper = calib_dumper.done()\n",
    "calib = sta.convert_to_chip(calib_dumper, lola.Chip())\n",
    "\n",
    "# disable neuron readout to CADC (observe correlation instead)\n",
    "for cadc_config in calib.cadc_readout_chains:\n",
    "    for channels in [cadc_config.channels_causal,\n",
    "                     cadc_config.channels_acausal]:\n",
    "        for channel_config in channels:\n",
    "            channel_config.enable_connect_neuron = False\n",
    "\n",
    "injected_readout = pynn.InjectedReadout()\n",
    "injected_readout.post_realtime.add(halco.SynramOnDLS())\n",
    "\n",
    "pynn_config = {\"initial_config\": calib,\n",
    "               \"injected_config\": injected_config,\n",
    "               \"injected_readout\": injected_readout}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d2118",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# generate input spiketrains:\n",
    "# spiketrain for noise row\n",
    "single_spiketrain_noise = np.arange(\n",
    "    parameters.init_duration.rescale(pq.ms).magnitude,\n",
    "    (parameters.init_duration + parameters.input_duration\n",
    "     ).rescale(pq.ms).magnitude,\n",
    "    parameters.wait_between_noise.rescale(pq.ms).magnitude)\n",
    "spiketrains_noise = [\n",
    "    np.concatenate([\n",
    "        single_spiketrain_noise\n",
    "        + i * parameters.row_duration.rescale(pq.ms).magnitude\n",
    "        for i in range(parameters.n_inputs * parameters.epochs_per_run)])]\n",
    "\n",
    "# spiketrain for each (target) input row\n",
    "spiketrains_per_input = []\n",
    "for input_row in range(parameters.n_inputs):\n",
    "    input_spikes = []\n",
    "    for row in range(parameters.n_inputs):\n",
    "        try:\n",
    "            wait_between_events = parameters.wait_between_events \\\n",
    "                / parameters.input_distribution[np.abs(row - input_row)]\n",
    "            input_spikes.append(np.arange(\n",
    "                0,\n",
    "                parameters.input_duration.rescale(pq.ms).magnitude,\n",
    "                wait_between_events.rescale(pq.ms).magnitude))\n",
    "        except IndexError:\n",
    "            input_spikes.append(np.array([]))\n",
    "    spiketrains_per_input.append(input_spikes)\n",
    "\n",
    "# shift spiketrains to appropriate start time, concatenate them\n",
    "spiketrains_per_epoch = []\n",
    "for row in range(parameters.n_inputs):\n",
    "    input_spikes = [\n",
    "        spiketrains_per_input[i][row]\n",
    "        + i * parameters.row_duration.rescale(pq.ms).magnitude\n",
    "        + parameters.init_duration.rescale(pq.ms).magnitude\n",
    "        for i in range(parameters.n_inputs)]\n",
    "    spiketrains_per_epoch.append(np.concatenate(input_spikes))\n",
    "\n",
    "# repeat spiketrains for multiple epochs\n",
    "spiketrains_multiple_epochs = []\n",
    "for row in range(parameters.n_inputs):\n",
    "    input_spikes = [\n",
    "        spiketrains_per_epoch[row]\n",
    "        + i * parameters.epoch_duration.rescale(pq.ms).magnitude\n",
    "        for i in range(parameters.epochs_per_run)]\n",
    "    spiketrains_multiple_epochs.append(np.concatenate(input_spikes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37396009",
   "metadata": {},
   "source": [
    "We’re now ready to start training. Executing the following cell will\n",
    "train 100 epochs (default). This will take a few minutes. You can re-run\n",
    "that cell (or select more epochs per cell execution) as long as you\n",
    "desire and the training should yield better and better results. After\n",
    "some 2000 epochs, the learned diagonal matrix will result in an (almost)\n",
    "perfect pong game. But even after a few hundred epochs, you should be\n",
    "able to observe an onset of the diagonal in the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8912c0f",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# select the number of epochs to train when executing the next cell:\n",
    "N_EPOCHS_TO_TRAIN = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de006bd4",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# initialize PyNN\n",
    "pynn.setup(**pynn_config)\n",
    "\n",
    "# setup input and output populations and projections\n",
    "pop_output = pynn.Population(\n",
    "    parameters.n_outputs, pynn.cells.HXNeuron())\n",
    "pop_input = pynn.Population(\n",
    "    parameters.n_inputs, pynn.cells.SpikeSourceArray(spike_times=spiketrains_multiple_epochs))\n",
    "pop_noise = pynn.Population(\n",
    "    1, pynn.cells.SpikeSourceArray(spike_times=spiketrains_noise))\n",
    "\n",
    "synapses = pynn.standardmodels.synapses.PlasticSynapse(\n",
    "    plasticity_rule=PlasticityRule(timer=plasticity_timer, same_id=0),\n",
    "    weight=logical_weights if logical_weights is not None\n",
    "    else np.ones((parameters.n_inputs, parameters.n_outputs), dtype=int))\n",
    "projection = pynn.Projection(\n",
    "    pop_input, pop_output, pynn.AllToAllConnector(),\n",
    "    synapse_type=synapses, receptor_type=\"excitatory\")\n",
    "\n",
    "synapses_noise = pynn.standardmodels.synapses.PlasticSynapse(\n",
    "    plasticity_rule=NoiseSynapseRule(timer=init_timer, same_id=1),\n",
    "    weight=63)\n",
    "projection_noise = pynn.Projection(\n",
    "    pop_noise, pop_output, pynn.AllToAllConnector(),\n",
    "    synapse_type=synapses_noise, receptor_type=\"excitatory\")\n",
    "\n",
    "output = widgets.Output()\n",
    "display(output)\n",
    "\n",
    "for epoch_id in range(N_EPOCHS_TO_TRAIN // parameters.epochs_per_run):\n",
    "    epoch = data.n_epochs_trained\n",
    "    if epoch >= parameters.noise_range_epochs:\n",
    "        print(\"Training finished!\")\n",
    "        plot_data = data.generate_plot(logical_weights)\n",
    "        plt.close()\n",
    "        output.clear_output(wait=True)\n",
    "        with output:\n",
    "            data.update_plot(plot_data, logical_weights)\n",
    "        break\n",
    "\n",
    "    pynn.run(parameters.epoch_duration.rescale(pq.ms).magnitude\n",
    "             * parameters.epochs_per_run)\n",
    "\n",
    "    # look up routing:\n",
    "    # The order of placed input rows on chip differs from the logical\n",
    "    # order of inputs. When looking at the weights read back from\n",
    "    # hardware, we need to adjust to the order of placed connections.\n",
    "    # We fill the array `routing` to contain the placed coordinate\n",
    "    # for each logical connection, based on the data from PyNN.\n",
    "    if epoch == 0:\n",
    "        connections = projection.connections\n",
    "        placed_connections = projection.placed_connections\n",
    "        routing = np.empty(\n",
    "            (parameters.n_inputs, parameters.n_outputs, 2), dtype=int)\n",
    "        for index, _ in enumerate(connections):\n",
    "            routing[connections[index].pop_pre_index,\n",
    "                    connections[index].pop_post_index] = \\\n",
    "                np.array([placed_connections[index][0].synapse_row,\n",
    "                          placed_connections[index][0].synapse_on_row])\n",
    "\n",
    "    post_realtime_reads = pynn.get_post_realtime_read()\n",
    "    weights = post_realtime_reads[halco.SynramOnDLS()].weights.to_numpy()\n",
    "\n",
    "    for run_epoch in range(parameters.epochs_per_run):\n",
    "        rewards = np.empty(parameters.n_inputs)\n",
    "        success = np.empty(parameters.n_inputs, dtype=bool)\n",
    "        for row in range(parameters.n_inputs):\n",
    "            # extract rewards and success from recording\n",
    "            data_index = row + parameters.n_inputs * run_epoch\n",
    "            success[row] = synapses.plasticity_rule.get_observable_array(\n",
    "                \"success\")[0][data_index].data[0]\n",
    "\n",
    "            # The reward was saved as a char array and needs to be\n",
    "            # converted back to a float:\n",
    "            raw_data = synapses.plasticity_rule.get_observable_array(\n",
    "                \"rewards\")[0][data_index].data\n",
    "            packed_data = struct.pack(\"4B\", *raw_data[:4][::-1])\n",
    "            rewards[row] = struct.unpack(\"f\", packed_data)[0]\n",
    "\n",
    "        data.reward_archive.append(rewards)\n",
    "        data.success_archive.append(success)\n",
    "\n",
    "    logical_weights = weights[routing[:, :, 0], routing[:, :, 1]]\n",
    "    data.mean_diagonal_weight.append(\n",
    "        np.mean(logical_weights[parameters.diagonal_entries()]))\n",
    "    data.mean_off_diagonal_weight.append(\n",
    "        np.mean(logical_weights[parameters.off_diagonal_entries()]))\n",
    "\n",
    "    projection.set(weight=logical_weights)\n",
    "\n",
    "    if epoch_id == 0:\n",
    "        with output:\n",
    "            plot_data = data.generate_plot(logical_weights)\n",
    "            plt.close()\n",
    "    output.clear_output(wait=True)\n",
    "    with output:\n",
    "        data.update_plot(plot_data, logical_weights)\n",
    "\n",
    "    pynn.reset()\n",
    "\n",
    "pynn.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0474583",
   "metadata": {},
   "source": [
    "In the plot above, a diagonal matrix should be visible after rougly a\n",
    "hundred epochs of training. Also, the success (red), indicating the\n",
    "performance of the network in the Pong game, should start to increase\n",
    "slightly.\n",
    "\n",
    "Now that the network has trained a bit, we can use the trained weights\n",
    "for an actual game of pong. The left player is controlled by an ideal\n",
    "weight matrix on a second set of hardware neurons, while the right\n",
    "player uses the weights trained above. To keep the animation fluent, the\n",
    "game is run in advance and animated only later, in a separate cell, so\n",
    "you can replay the same game multiple times.\n",
    "\n",
    "The performance of the agent on the right may be better than the\n",
    "accuracy reported above, since we don’t add any noise here - but need\n",
    "the noise during traing to enable exploration. Still, after 100 epochs,\n",
    "the right player will lose the game rather quickly, and after some 300\n",
    "epochs, it will play for quite some time, possibly reaching the end of\n",
    "the pre-computed game (where we report the game ended in a tie).\n",
    "\n",
    "You can switch between training and animation as you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675ffc22",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# initialize a new pong game - this clears the scores!\n",
    "pong_game = PongGame(\n",
    "    parameters=parameters, pynn_config=pynn_config,\n",
    "    spiketrains_per_input=spiketrains_per_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae19d5",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# run a pong game using the weights trained above. This takes a few seconds since we run it on chip.\n",
    "pong_game.run(learned_weights=logical_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28394f0d",
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "# Display the animation of the game - re-executing will replay the same game.\n",
    "if len(pong_game.spiketrains_per_input) == 0:\n",
    "    raise AssertionError(\"In order to run the game on chip, please run the two cells above!\")\n",
    "else:\n",
    "    pong_game.animate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd715e60",
   "metadata": {},
   "source": [
    "Finally, we want to show you that this setup is capable of training even\n",
    "a larger matrix with smaller paddles - a more difficult task than with the\n",
    "default parameters above. Here, we need to train longer, and training for\n",
    "about 1000 epochs takes around an hour - hence we provide a plot of that here.\n",
    "But feel free to tweak a few of the parameters (defined at the start of\n",
    "the notebook), and continue training the network after the tutorial!\n",
    "This plot was generated using the unmodified\n",
    "`parameters = Parameters()`, i.e. without the adjustments in the\n",
    "default notebook.\n",
    "\n",
    "<img src=\"_static/tutorial/pong_training_996epochs.png\" alt=\"Pong performance after 1000 epochs\" style=\"width:729px;\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004f991",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "The notebook was developed in the Electronic Vision(s) group in 2023.\n",
    "The main author is Johannes Weis."
   ]
  }
 ],
 "metadata": {
  "date": 1741770895.8384297,
  "filename": "ts_07-pong.rst",
  "kernelspec": {
   "display_name": "EBRAINS-experimental",
   "language": "python",
   "name": "ebrains-experimental"
  },
  "title": "Pong"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}